<<<<<<< HEAD
{"nbformat":4,"nbformat_minor":5,"metadata":{"accelerator":"GPU","colab":{"name":"colab_training_and_evaluation.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MZmtW9scbJ9Y","executionInfo":{"status":"ok","timestamp":1632422718135,"user_tz":240,"elapsed":520,"user":{"displayName":"Jeremy Rothschild","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64","userId":"12754514505135179603"}},"outputId":"af1efac7-2891-49b0-ca37-afde5eb8d45a"},"source":["IN_COLAB = 'google.colab' in str(get_ipython())\n","\n","if IN_COLAB:\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=True)\n","    %cd /content/drive/MyDrive/Github/Abstract-generator/bumbleBERT/notebooks"],"id":"MZmtW9scbJ9Y","execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Github/Abstract-generator/bumbleBERT/notebooks\n","Running in colab: True\n","Training mode: True\n"]}]},{"cell_type":"code","metadata":{"id":"A5-WBJCzEE70"},"source":["TRAIN = True\n","\n","if IN_COLAB:  \n","    batch_size = 10 #32\n","    val_batch_size = 10 #32\n","    epochs = 10  # The number of epochs\n","else:\n","    batch_size = 128       # 3\n","    val_batch_size = 128  # 3\n","    epochs = 200  # The number of epochs\n","\n","print('Running in colab:', IN_COLAB)\n","print('Training mode:', TRAIN)"],"id":"A5-WBJCzEE70","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hokd2wsGcghW","executionInfo":{"status":"ok","timestamp":1632424121964,"user_tz":240,"elapsed":3678,"user":{"displayName":"Jeremy Rothschild","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64","userId":"12754514505135179603"}}},"source":["%%capture\n","!pip install feedparser tokenizers transformers;"],"id":"hokd2wsGcghW","execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"04f6ae9e","executionInfo":{"status":"ok","timestamp":1632422319956,"user_tz":240,"elapsed":3839,"user":{"displayName":"Jeremy Rothschild","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64","userId":"12754514505135179603"}}},"source":["import os, torch, time, math, sys, re, csv\n","import numpy as np\n","\n","sys.path.append('..' + os.sep )\n","from src import default\n","\n","from src.data import download as dl, tokenization as tkn, custom_dataset as cd\n","\n","from torch.utils.data import DataLoader\n","from src.model.transformer_hf import TransformerModel\n","from src.model.batching import CustomBatch\n","from src.model.generate_text import gen_some_text\n","from src.model.train_evaluate import train, evaluate\n","#from src.model.transformer import make_gpt_model # imports don't work\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"id":"04f6ae9e","execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"904013cd"},"source":["### Parameters"],"id":"904013cd"},{"cell_type":"code","metadata":{"id":"da73442b","executionInfo":{"status":"ok","timestamp":1632422325957,"user_tz":240,"elapsed":244,"user":{"displayName":"Jeremy Rothschild","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64","userId":"12754514505135179603"}}},"source":["# ARCHITECTURE\n","maxLen     = 35 # maximum sentence length\n","vocabSize  = None # None if you want to let tokenizer do its thing\n","emsize     = 512 # embedding dimension\n","nhid       = 2048 # the dimension of the feedforward network model in torch.nn.TransformerEncoder\n","nlayers    = 12 # the number of torch.nn.TransformerEncoderLayer in torch.nn.TransformerEncoder\n","nhead      = 8 # the number of heads in the multiheadattention models\n","dropout    = 0.2 # the dropout value\n","\n","# TOKENIZER\n","tknzerType = 'BPE' # type of tokenizing algorithm\n","trainTokenizer = True # whether to train a new tokenizer or use one already trained"],"id":"da73442b","execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"33bf83d8"},"source":["### Download Dataset"],"id":"33bf83d8"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"67302c43","executionInfo":{"status":"ok","timestamp":1632422331293,"user_tz":240,"elapsed":645,"user":{"displayName":"Jeremy Rothschild","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64","userId":"12754514505135179603"}},"outputId":"7f7754ad-6e1b-4d0d-d80c-20686ed70e23"},"source":["# download data\n","nbrResults = 10**4 # number of data samples to download\n","filename = f'arxiv_{nbrResults}'\n","extension = '.csv'\n","filepath = default.RAW_DATA_DIR + os.sep + filename + extension\n","\n","if not os.path.exists(filepath):\n","    dl.arxiv_api( default.RAW_DATA_DIR, filepath, max_results=nbrResults ) # TODO : CHANGE SO THAT NOT CONSTANTLY LOADING DATA\n","print(f'>> Using {filename} for training <<')"],"id":"67302c43","execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":[">> Using arxiv_10000 for training <<\n"]}]},{"cell_type":"markdown","metadata":{"id":"21983a34"},"source":["### Format Dataset\n","\n","Uses a custom dataset class, which is an iterable and callable structure that returns a sample from our dataset. Within this custom dataset, can determine all preprocessing."],"id":"21983a34"},{"cell_type":"code","metadata":{"id":"015ae225","executionInfo":{"status":"ok","timestamp":1632422336336,"user_tz":240,"elapsed":2574,"user":{"displayName":"Jeremy Rothschild","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64","userId":"12754514505135179603"}}},"source":["# create dataset\n","dataset = cd.ArxivDataset(filepath)"],"id":"015ae225","execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"11976e8e"},"source":["### Training Tokenizer\n","\n","Training of a custom tokenizer. Many options possible here, check the tokenizer training functions to try out various strategies. If he tokenizer for the dataset has already been trained, no need to run this again."],"id":"11976e8e"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d3a132c4","executionInfo":{"status":"ok","timestamp":1632422343490,"user_tz":240,"elapsed":4557,"user":{"displayName":"Jeremy Rothschild","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64","userId":"12754514505135179603"}},"outputId":"00864287-887d-41d6-c0c1-172eefa595b5"},"source":["trainTokenizer: _ = tkn.train_custom_tokenizer(tknzerType, dataset, filename\n","                                            , default.TOK_DIR\n","                                            , vocabSize\n","                                            , **default.special_token_lst)"],"id":"d3a132c4","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Warning : overwriting previously save tokenizer with                        same filename ( arxiv_10000 ).\n"]}]},{"cell_type":"markdown","metadata":{"id":"f3089723"},"source":["### Loading Tokenizer and Splitting Datasets\n","\n","For some reason, torch tokenizers are not callable as trained. This is confusing, but c'est la vie! Instead, need to load it from file it was saved in using the PreTrainedTokenizerFast class (__call__) implemented in here. Once that's done, you can add this tokenizer as a transform to your dataset! Useful.\n","\n","We also split the dataset here into training, testing and validation datasets."],"id":"f3089723"},{"cell_type":"code","metadata":{"id":"fe434fb7","executionInfo":{"status":"ok","timestamp":1632422348108,"user_tz":240,"elapsed":214,"user":{"displayName":"Jeremy Rothschild","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64","userId":"12754514505135179603"}}},"source":["tknzrFile = default.TOK_DIR + os.sep + filename + '_' + tknzerType + '.json'\n","\n","# load PreTrainedTokenizerFast, for __call__. __call__ not implemented in\n","# the base Tokenizer class... that sounds silly, but it is what it is\n","tknzr = tkn.load_tokenizer(tknzrFile, **default.special_token_lst)\n","\n","if vocabSize is None: vocabSize = tknzr.vocab_size\n","\n","# set tknzr as the transform\n","dataset.set_transform( tknzr )\n","\n","# separate dataset into train, test valid TODO : make into a function\n","fracTrain, fracTest, fracVal = ( 0.7, 0.2, 0.1)\n","trainTestVal = [ np.floor(fracTrain*len(dataset))\\\n","                    , np.floor(fracTest*len(dataset))\\\n","                    , len(dataset) - ( np.floor( fracTrain*len(dataset) ) +\n","                    np.floor( fracTest*len(dataset) ) )\n","                    ]\n","\n","trainDataset, testDataset, valDataset =\\\n","        torch.utils.data.random_split(dataset, [int(x) for x in trainTestVal]\n","                                , generator=torch.Generator().manual_seed(42) )\n"],"id":"fe434fb7","execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4bba4cb9"},"source":["### Creating DataLoaders\n","\n","Training is done on batches, so we need a way to extract groupings of the data in the appropriate format for our transformer model.\n","Note that for transformers which we are training, dataloaders outputs both src (x[:-1] and tgt ([1:]).\n","The collation of batches for different transformer models we have vary. For HuggingFace it's ( maxLen x batch_size ) whereas I think that the Annotated Transformer has ( batch_size x maxLen ).\n","\n","NOTE : Do not use the tokenizer before the training if you use num_workers>0!\n","FastTokenizer does not play nicely with forking if you use it before the forking of your data:\n","https://stackoverflow.com/questions/62691279/how-to-disable-tokenizers-parallelism-true-false-warning"],"id":"4bba4cb9"},{"cell_type":"code","metadata":{"id":"c11048fc","executionInfo":{"status":"ok","timestamp":1632422351212,"user_tz":240,"elapsed":502,"user":{"displayName":"Jeremy Rothschild","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64","userId":"12754514505135179603"}}},"source":["# create dataloaders\n","# uses collate function to transform batch to correct dimensions\n","def collate_wrapper(batch):\n","    return CustomBatch(batch, dim=0, maxLenModel=maxLen, padValue=tknzr.get_vocab()[\"<pad>\"])\n","\n","# dataloader for training\n","trainDataLoader = DataLoader(trainDataset, batch_size=batch_size, shuffle=True\n","                                        , num_workers=2\n","                                        , collate_fn=collate_wrapper\n","                                        , pin_memory=True\n","                                        )\n","# dataloader for validation\n","valDataLoader = DataLoader(valDataset, batch_size=val_batch_size, shuffle=True\n","                                        , num_workers=2\n","                                        , collate_fn=collate_wrapper\n","                                        , pin_memory=True\n","                                        )"],"id":"c11048fc","execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e3955854"},"source":["### Selecting model\n","\n","Here we choose which model we shall use for training. For now, I've selected the black box Transformer from HuggingFace because the collate_fn I've written gives the correct input size force it... however this can easily be changed! "],"id":"e3955854"},{"cell_type":"code","metadata":{"id":"6de7d252","executionInfo":{"status":"ok","timestamp":1632422760770,"user_tz":240,"elapsed":969,"user":{"displayName":"Jeremy Rothschild","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64","userId":"12754514505135179603"}}},"source":["# transformer from huggingface\n","# TODO : Change to the Annotated Transformer if I want\n","model = TransformerModel(vocabSize, emsize, nhead, nhid, nlayers, dropout).to(device)\n","\n","# criterion\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","# optimizer\n","# learning rate Matt used with Adam is 0.5\n","paramsAdam  = [{'params' : model.parameters(), 'lr' : 1e-3, 'betas' : (0.9, 0.999), 'eps' : 1e-08, 'weight_decay' : 0.0}]\n","paramsAdamW = [{'params' : model.parameters(), 'lr' : 5e-5, 'betas' : (0.9, 0.999), 'eps' : 1e-08, 'weight_decay' : 0.0}]\n","paramsSGD   = [{'params' : model.parameters(), 'lr' : 0.5, 'momentum' : 0.0, 'dampening' : 0.0, 'weight_decay' : 0.0}]\n","\n","#optimizer = torch.optim.SGD( paramsSGD )\n","#optimizer = torch.optim.Adam( paramsAdam )\n","optimizer = torch.optim.AdamW( paramsAdamW )\n","\n","# scheduler\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)"],"id":"6de7d252","execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9780d86f"},"source":["### Training\n","\n","Training loop!"],"id":"9780d86f"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"75775f0e","executionInfo":{"status":"ok","timestamp":1632423535568,"user_tz":240,"elapsed":745071,"user":{"displayName":"Jeremy Rothschild","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64","userId":"12754514505135179603"}},"outputId":"00a9192c-d755-4c4b-a3f3-cf15547131fe"},"source":["best_val_loss = float(\"inf\")\n","best_model = None\n","for epoch in range(1, epochs + 1):\n","    epoch_start_time = time.time()\n","    train( model, maxLen, trainDataLoader, device, vocabSize, epoch, optimizer, scheduler, criterion)\n","    val_loss = evaluate(model, maxLen, valDataLoader, len(valDataset), device, vocabSize, criterion)\n","    print('-' * 89)\n","    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n","          'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n","                                     val_loss, math.exp(val_loss)))\n","                                     # Why is math.exp so large????\n","    print('-' * 89)\n","\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        best_model = model\n","\n","    scheduler.step()\n","\n","    \n","# save best model (two methods)\n","modelFull = default.MODEL_DIR + os.sep + f'{filename}_epoch{epochs}.pth'\n","modelWeights = default.MODEL_DIR + os.sep + f'{filename}_weights_epoch{epochs}.pth'\n","modelFullBest = default.MODEL_DIR + os.sep + f'{filename}_epoch{epochs}_best.pth'\n","modelWeightsBest = default.MODEL_DIR + os.sep + f'{filename}_weights_epoch{epochs}_best.pth'\n","# approach 1: save model (class) entirely (uses pickle)\n","torch.save(model, modelFull)\n","torch.save(best_model, modelFullBest)\n","# approach 2: save model weights\n","torch.save(best_model.state_dict(), modelWeightsBest)"],"id":"75775f0e","execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["| epoch   1 |   200/  429 batches | lr 0.00 | ms/batch 167.55 | loss  7.57 | ppl  1940.42\n","| epoch   1 |   400/  429 batches | lr 0.00 | ms/batch 162.99 | loss  6.45 | ppl   633.79\n","-----------------------------------------------------------------------------------------\n","| end of epoch   1 | time: 73.09s | valid loss  6.11 | valid ppl   449.32\n","-----------------------------------------------------------------------------------------\n","| epoch   2 |   200/  429 batches | lr 0.00 | ms/batch 164.87 | loss  5.95 | ppl   384.57\n","| epoch   2 |   400/  429 batches | lr 0.00 | ms/batch 163.52 | loss  5.78 | ppl   324.70\n","-----------------------------------------------------------------------------------------\n","| end of epoch   2 | time: 72.68s | valid loss  5.66 | valid ppl   286.69\n","-----------------------------------------------------------------------------------------\n","| epoch   3 |   200/  429 batches | lr 0.00 | ms/batch 164.88 | loss  5.59 | ppl   268.71\n","| epoch   3 |   400/  429 batches | lr 0.00 | ms/batch 163.65 | loss  5.44 | ppl   230.51\n","-----------------------------------------------------------------------------------------\n","| end of epoch   3 | time: 72.74s | valid loss  5.49 | valid ppl   243.00\n","-----------------------------------------------------------------------------------------\n","| epoch   4 |   200/  429 batches | lr 0.00 | ms/batch 165.30 | loss  5.32 | ppl   204.24\n","| epoch   4 |   400/  429 batches | lr 0.00 | ms/batch 163.47 | loss  5.26 | ppl   191.73\n","-----------------------------------------------------------------------------------------\n","| end of epoch   4 | time: 72.78s | valid loss  5.35 | valid ppl   210.87\n","-----------------------------------------------------------------------------------------\n","| epoch   5 |   200/  429 batches | lr 0.00 | ms/batch 165.04 | loss  5.11 | ppl   166.06\n","| epoch   5 |   400/  429 batches | lr 0.00 | ms/batch 163.51 | loss  5.08 | ppl   160.53\n","-----------------------------------------------------------------------------------------\n","| end of epoch   5 | time: 72.69s | valid loss  5.24 | valid ppl   189.40\n","-----------------------------------------------------------------------------------------\n","| epoch   6 |   200/  429 batches | lr 0.00 | ms/batch 164.91 | loss  4.94 | ppl   139.87\n","| epoch   6 |   400/  429 batches | lr 0.00 | ms/batch 163.52 | loss  4.93 | ppl   138.87\n","-----------------------------------------------------------------------------------------\n","| end of epoch   6 | time: 72.73s | valid loss  5.18 | valid ppl   176.98\n","-----------------------------------------------------------------------------------------\n","| epoch   7 |   200/  429 batches | lr 0.00 | ms/batch 165.04 | loss  4.82 | ppl   123.41\n","| epoch   7 |   400/  429 batches | lr 0.00 | ms/batch 163.31 | loss  4.79 | ppl   120.72\n","-----------------------------------------------------------------------------------------\n","| end of epoch   7 | time: 72.69s | valid loss  5.13 | valid ppl   169.61\n","-----------------------------------------------------------------------------------------\n","| epoch   8 |   200/  429 batches | lr 0.00 | ms/batch 165.33 | loss  4.69 | ppl   109.14\n","| epoch   8 |   400/  429 batches | lr 0.00 | ms/batch 163.38 | loss  4.67 | ppl   107.16\n","-----------------------------------------------------------------------------------------\n","| end of epoch   8 | time: 72.77s | valid loss  5.09 | valid ppl   162.32\n","-----------------------------------------------------------------------------------------\n","| epoch   9 |   200/  429 batches | lr 0.00 | ms/batch 164.80 | loss  4.57 | ppl    96.86\n","| epoch   9 |   400/  429 batches | lr 0.00 | ms/batch 163.54 | loss  4.58 | ppl    97.17\n","-----------------------------------------------------------------------------------------\n","| end of epoch   9 | time: 72.67s | valid loss  5.05 | valid ppl   155.72\n","-----------------------------------------------------------------------------------------\n","| epoch  10 |   200/  429 batches | lr 0.00 | ms/batch 165.52 | loss  4.47 | ppl    87.54\n","| epoch  10 |   400/  429 batches | lr 0.00 | ms/batch 163.70 | loss  4.48 | ppl    87.81\n","-----------------------------------------------------------------------------------------\n","| end of epoch  10 | time: 72.89s | valid loss  5.02 | valid ppl   152.11\n","-----------------------------------------------------------------------------------------\n"]}]},{"cell_type":"markdown","metadata":{"id":"XM5G4vD0q9TZ"},"source":["### Text Generation\n","\n","Here I've simply taken the code Matt uses to generate text."],"id":"XM5G4vD0q9TZ"},{"cell_type":"code","metadata":{"id":"eb6acee1"},"source":["if not TRAIN:\n","    customFilename = 'arxiv_10000'\n","    customEpochs = 10\n","    modelFull = default.MODEL_DIR + os.sep + f'{customFilename}_epoch{customEpochs}_best.pth'\n","    modelWeights = default.MODEL_DIR + os.sep + f'{customFilename}_weights_epoch{customEpochs}_best.pth'\n","    \n","    # approach 1: load model (class) entirely (uses pickle)\n","    modelFullLoad = torch.load(modelFull, map_location=device)\n","\n","    # approach 2: load model weights, need to have some parameter or something \n","    modelLoad = TransformerModel(vocabSize, emsize, nhead, nhid, nlayers, dropout).to(device)\n","    modelWeightsLoad = modelLoad.load_state_dict( torch.load(modelWeights) )"],"id":"eb6acee1","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SoGylu7hq7kI","executionInfo":{"status":"ok","timestamp":1632423598082,"user_tz":240,"elapsed":10928,"user":{"displayName":"Jeremy Rothschild","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64","userId":"12754514505135179603"}},"outputId":"b5d43790-e2bf-44a5-95f8-2afb5c481e8c"},"source":["# inspect both models\n","#print('model_A info...\\n', modelFullLoad)\n","#print('\\nmodel_B info...\\n', modelWeightsLoad)\n","\n","#print('model_A == model_B:', modelFullLoad == modelWeightsLoad)\n","#model = modelFullLoad\n","# Text generation example\n","\n","#model = modelLoad\n","prompt = 'Electrons are protons. They are both really small and make my head spin when I think about it too hard. Protons are also electrons.'\n","ngen = 100\n","decode_style = 'greedy'\n","model.to('cpu')\n","generated_text = gen_some_text(\n","    model, tknzr, 'cpu', maxLen, text_prompt=prompt, tokens_to_gen=ngen, vis=False,\n","    decode_style=decode_style)\n","print(\"Text prompt:\\n\", prompt)\n","print(\"Number of tokens to generate:\", ngen)\n","print(\"Generated_text:\\n\", generated_text)\n","\n","# TODO: alternative generation\n","# currently 'greedy method'\n","# see: https://huggingface.co/blog/how-to-generate"],"id":"SoGylu7hq7kI","execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([    1,  2961,   212,  2625,   125,  3509,   212,   647, 16714,   782,\n","          146,  2771, 12808,  6830,   271,   818,   245, 13380,  1440,   399,\n","         4644,  2415,   125, 24926,   212,   562,   201,   125,     2])\n","29\n","tensor([[    1],\n","        [ 2961],\n","        [  212],\n","        [ 2625],\n","        [  125],\n","        [ 3509],\n","        [  212],\n","        [  647],\n","        [16714],\n","        [  782],\n","        [  146],\n","        [ 2771],\n","        [12808],\n","        [ 6830],\n","        [  271],\n","        [  818],\n","        [  245],\n","        [13380],\n","        [ 1440],\n","        [  399],\n","        [ 4644],\n","        [ 2415],\n","        [  125],\n","        [24926],\n","        [  212],\n","        [  562],\n","        [  201],\n","        [  125],\n","        [    2]])\n","tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0.]])\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","next_guess_int, next_guess_string: tensor(0) <pad>\n","Text prompt:\n"," Electrons are protons. They are both really small and make my head spin when I think about it too hard. Protons are also electrons.\n","Number of tokens to generate: 100\n","Generated_text:\n"," Electrons are protons. They are both really small and make my head spin when I think about it too hard. Protons are also electrons. <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"csNTLYQ3otnm","executionInfo":{"status":"ok","timestamp":1629397304410,"user_tz":240,"elapsed":6,"user":{"displayName":"Jeremy Rothschild","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64","userId":"12754514505135179603"}},"outputId":"6796e070-10a6-4446-bc17-8e971fcb5da4"},"source":["tknzr.decode([107])"],"id":"csNTLYQ3otnm","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["' the'"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"P4EWiRBvpb0T"},"source":[""],"id":"P4EWiRBvpb0T","execution_count":null,"outputs":[]}]}
=======
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "MZmtW9scbJ9Y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22301,
     "status": "ok",
     "timestamp": 1628862364306,
     "user": {
      "displayName": "Jeremy Rothschild",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64",
      "userId": "12754514505135179603"
     },
     "user_tz": 240
    },
    "id": "MZmtW9scbJ9Y",
    "outputId": "ccd11b5c-cfac-48ff-8fd0-ff5657730b50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in colab:  False\n",
      "Training mode:  True\n"
     ]
    }
   ],
   "source": [
    "IN_COLAB = 'google.colab' in str(get_ipython())\n",
    "TRAIN = True\n",
    "LOAD_MODEL = None\n",
    "TRAIN_TOKENIZER = True\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    %cd /content/drive/MyDrive/Github/Abstract-generator/bumbleBERT/notebooks\n",
    "    batch_size = 10 #32\n",
    "    eval_batch_size = 10 #32\n",
    "    epochs = 10  # The number of epochs\n",
    "    !pip install feedparser tokenizers transformers\n",
    "else:\n",
    "    batch_size = 32       # 3\n",
    "    val_batch_size = 32  # 3\n",
    "    epochs = 10  # The number of epochs\n",
    "\n",
    "print('Running in colab: ', IN_COLAB)\n",
    "print('Training mode: ', TRAIN)\n",
    "if LOAD_MODEL is not None:\n",
    "    print('Using previous model: ', LOAD_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "04f6ae9e",
   "metadata": {
    "executionInfo": {
     "elapsed": 343,
     "status": "ok",
     "timestamp": 1628862465466,
     "user": {
      "displayName": "Jeremy Rothschild",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64",
      "userId": "12754514505135179603"
     },
     "user_tz": 240
    },
    "id": "04f6ae9e"
   },
   "outputs": [],
   "source": [
    "import os, torch, time, math, sys, re, csv\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('..' + os.sep )\n",
    "from src import default\n",
    "\n",
    "from src.data import download as dl, tokenization as tkn, custom_dataset as cd\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from src.model.transformer_hf import TransformerModel\n",
    "from src.model.batching import CustomBatch\n",
    "from src.model.generate_text import gen_some_text\n",
    "#from src.model.train_evaluate import train, evaluate\n",
    "#from src.model.transformer import make_gpt_model # imports don't work\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904013cd",
   "metadata": {
    "id": "904013cd"
   },
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "da73442b",
   "metadata": {
    "executionInfo": {
     "elapsed": 161,
     "status": "ok",
     "timestamp": 1628862477958,
     "user": {
      "displayName": "Jeremy Rothschild",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64",
      "userId": "12754514505135179603"
     },
     "user_tz": 240
    },
    "id": "da73442b"
   },
   "outputs": [],
   "source": [
    "# ARCHITECTURE\n",
    "if LOAD_MODEL is None:\n",
    "    params = {\n",
    "                'maxLen'     : 25, # maximum sentence length\n",
    "                'vocabSize'    : None, # None if you want to let tokenizer do its thing\n",
    "                'emsize'     : 512, # embedding dimension\n",
    "                'nhid'       : 2048, # the dimension of the feedforward network model in torch.nn.TransformerEncoder\n",
    "                'nlayers'    : 12, # the number of torch.nn.TransformerEncoderLayer in torch.nn.TransformerEncoder\n",
    "                'nhead'      : 8, # the number of heads in the multiheadattention models\n",
    "                'dropout'    : 0.1 # the dropout value\n",
    "            }\n",
    "\n",
    "    # TOKENIZER\n",
    "    tknzerType = 'BPE' # type of tokenizing algorithm\n",
    "    \n",
    "else:\n",
    "    print(\"TODO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bf83d8",
   "metadata": {
    "id": "33bf83d8"
   },
   "source": [
    "### Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "67302c43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 345,
     "status": "ok",
     "timestamp": 1628862544480,
     "user": {
      "displayName": "Jeremy Rothschild",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64",
      "userId": "12754514505135179603"
     },
     "user_tz": 240
    },
    "id": "67302c43",
    "outputId": "b712b14b-c212-4ffd-cc2d-347ce05a0b92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Using arxiv_1000 for training <<\n"
     ]
    }
   ],
   "source": [
    "# download data\n",
    "nbrResults = 10**3 # number of data samples to download\n",
    "filename = f'arxiv_{nbrResults}'\n",
    "extension = '.csv'\n",
    "filepath = default.RAW_DATA_DIR + os.sep + filename + extension\n",
    "\n",
    "if not os.path.exists(filepath):\n",
    "    dl.arxiv_api( default.RAW_DATA_DIR, filepath, max_results=nbrResults ) # TODO : CHANGE SO THAT NOT CONSTANTLY LOADING DATA\n",
    "print(f'>> Using {filename} for training <<')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21983a34",
   "metadata": {
    "id": "21983a34"
   },
   "source": [
    "### Format Dataset\n",
    "\n",
    "Uses a custom dataset class, which is an iterable and callable structure that returns a sample from our dataset. Within this custom dataset, can determine all preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "015ae225",
   "metadata": {
    "executionInfo": {
     "elapsed": 1682,
     "status": "ok",
     "timestamp": 1628862556745,
     "user": {
      "displayName": "Jeremy Rothschild",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64",
      "userId": "12754514505135179603"
     },
     "user_tz": 240
    },
    "id": "015ae225"
   },
   "outputs": [],
   "source": [
    "# create dataset\n",
    "dataset = cd.ArxivDataset(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11976e8e",
   "metadata": {
    "id": "11976e8e"
   },
   "source": [
    "### Training Tokenizer\n",
    "\n",
    "Training of a custom tokenizer. Many options possible here, check the tokenizer training functions to try out various strategies. If he tokenizer for the dataset has already been trained, no need to run this again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d3a132c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3244,
     "status": "ok",
     "timestamp": 1626462968429,
     "user": {
      "displayName": "Jeremy Rothschild",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64",
      "userId": "12754514505135179603"
     },
     "user_tz": 240
    },
    "id": "d3a132c4",
    "outputId": "772cdfac-63bb-48ad-e4ea-d45eff5cb88c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning : overwriting previously save tokenizer with                        same filename ( arxiv_1000 ).\n"
     ]
    }
   ],
   "source": [
    "if ( (LOAD_MODEL is None) and TRAIN_TOKENIZER):\n",
    "    trainTokenizer: _ = tkn.train_custom_tokenizer(tknzerType, \n",
    "                                                   dataset, \n",
    "                                                   filename,\n",
    "                                                   default.TOK_DIR,\n",
    "                                                   params['vocabSize'],\n",
    "                                                   **default.special_token_lst\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3089723",
   "metadata": {
    "id": "f3089723"
   },
   "source": [
    "### Loading Tokenizer and Splitting Datasets\n",
    "\n",
    "For some reason, torch tokenizers are not callable as trained. This is confusing, but c'est la vie! Instead, need to load it from file it was saved in using the PreTrainedTokenizerFast class (__call__) implemented in here. Once that's done, you can add this tokenizer as a transform to your dataset! Useful.\n",
    "\n",
    "We also split the dataset here into training, testing and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fe434fb7",
   "metadata": {
    "executionInfo": {
     "elapsed": 626,
     "status": "ok",
     "timestamp": 1628862565146,
     "user": {
      "displayName": "Jeremy Rothschild",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64",
      "userId": "12754514505135179603"
     },
     "user_tz": 240
    },
    "id": "fe434fb7"
   },
   "outputs": [],
   "source": [
    "tknzrFile = default.TOK_DIR + os.sep + filename + '_' + tknzerType + '.json'\n",
    "\n",
    "# load PreTrainedTokenizerFast, for __call__. __call__ not implemented in\n",
    "# the base Tokenizer class... that sounds silly, but it is what it is\n",
    "tknzr = tkn.load_tokenizer(tknzrFile, **default.special_token_lst)\n",
    "\n",
    "if params['vocabSize'] is None: params['vocabSize'] = tknzr.vocab_size\n",
    "\n",
    "# set tknzr as the transform\n",
    "dataset.set_transform( tknzr )\n",
    "\n",
    "# separate dataset into train, test valid TODO : make into a function\n",
    "fracTrain, fracTest, fracVal = ( 0.7, 0.2, 0.1)\n",
    "trainTestVal = [ np.floor(fracTrain*len(dataset))\\\n",
    "                    , np.floor(fracTest*len(dataset))\\\n",
    "                    , len(dataset) - ( np.floor( fracTrain*len(dataset) ) +\n",
    "                    np.floor( fracTest*len(dataset) ) )\n",
    "                    ]\n",
    "\n",
    "trainDataset, testDataset, valDataset =\\\n",
    "        torch.utils.data.random_split(dataset,\n",
    "                                      [int(x) for x in trainTestVal],\n",
    "                                      generator=torch.Generator().manual_seed(42) \n",
    "                                     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bba4cb9",
   "metadata": {
    "id": "4bba4cb9"
   },
   "source": [
    "### Creating DataLoaders\n",
    "\n",
    "Training is done on batches, so we need a way to extract groupings of the data in the appropriate format for our transformer model.\n",
    "Note that for transformers which we are training, dataloaders outputs both src (x[:-1] and tgt ([1:]).\n",
    "The collation of batches for different transformer models we have vary. For HuggingFace it's ( maxLen x batch_size ) whereas I think that the Annotated Transformer has ( batch_size x maxLen ).\n",
    "\n",
    "NOTE : Do not use the tokenizer before the training if you use num_workers>0!\n",
    "FastTokenizer does not play nicely with forking if you use it before the forking of your data:\n",
    "https://stackoverflow.com/questions/62691279/how-to-disable-tokenizers-parallelism-true-false-warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c11048fc",
   "metadata": {
    "executionInfo": {
     "elapsed": 151,
     "status": "ok",
     "timestamp": 1628862600927,
     "user": {
      "displayName": "Jeremy Rothschild",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64",
      "userId": "12754514505135179603"
     },
     "user_tz": 240
    },
    "id": "c11048fc"
   },
   "outputs": [],
   "source": [
    "# create dataloaders\n",
    "# uses collate function to transform batch to correct dimensions\n",
    "def collate_wrapper(batch):\n",
    "    return CustomBatch(batch,\n",
    "                       dim = 0,\n",
    "                       maxLenModel = params['maxLen'],\n",
    "                       padValue = tknzr.get_vocab()[\"<pad>\"]\n",
    "                      )\n",
    "\n",
    "# dataloader for training\n",
    "trainDataLoader = DataLoader(trainDataset,\n",
    "                             batch_size = batch_size,\n",
    "                             shuffle = True,\n",
    "                             num_workers = 2,\n",
    "                             collate_fn = collate_wrapper,\n",
    "                             pin_memory = True\n",
    "                             )\n",
    "# dataloader for validation\n",
    "valDataLoader = DataLoader(valDataset, \n",
    "                           batch_size = val_batch_size,\n",
    "                           shuffle = True,\n",
    "                           num_workers = 2,\n",
    "                           collate_fn = collate_wrapper,\n",
    "                           pin_memory = True,\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3955854",
   "metadata": {
    "id": "e3955854"
   },
   "source": [
    "### Selecting model\n",
    "\n",
    "Here we choose which model we shall use for training. For now, I've selected the black box Transformer from HuggingFace because the collate_fn I've written gives the correct input size force it... however this can easily be changed! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6de7d252",
   "metadata": {
    "executionInfo": {
     "elapsed": 870,
     "status": "ok",
     "timestamp": 1628862621722,
     "user": {
      "displayName": "Jeremy Rothschild",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64",
      "userId": "12754514505135179603"
     },
     "user_tz": 240
    },
    "id": "6de7d252"
   },
   "outputs": [],
   "source": [
    "# transformer from huggingface\n",
    "# TODO : Change to the Annotated Transformer if I want\n",
    "model = TransformerModel(params['vocabSize'],\n",
    "                         params['emsize'], \n",
    "                         params['nhead'], \n",
    "                         params['nhid'], \n",
    "                         params['nlayers'], \n",
    "                         params['dropout']\n",
    "                        ).to(device)\n",
    "\n",
    "# criterion\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "# learning rate Matt used with Adam is 0.5\n",
    "paramsAdam  = [{'params' : model.parameters(),\n",
    "                'lr'     : 0.5, 'betas' : (0.9, 0.999),\n",
    "                'eps'    : 1e-08, 'weight_decay' : 0.0\n",
    "               }\n",
    "              ]\n",
    "paramsAdamW = [{'params' : model.parameters(),\n",
    "                'lr'     : 5e-5,\n",
    "                'betas'  : (0.9, 0.999),\n",
    "                'eps'    : 1e-08,\n",
    "                'weight_decay' : 0.0\n",
    "               }\n",
    "              ]\n",
    "paramsSGD   = [{'params'    : model.parameters(),\n",
    "                'lr'        : 0.5,\n",
    "                'momentum'  : 0.0,\n",
    "                'dampening' : 0.0,\n",
    "                'weight_decay' : 0.0\n",
    "               }\n",
    "              ]\n",
    "\n",
    "optimizer = torch.optim.SGD( paramsSGD )\n",
    "#optimizer = torch.optim.Adam( paramsAdam )\n",
    "#optimizer = torch.optim.AdamW( paramsAdamW )\n",
    "\n",
    "# scheduler\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9780d86f",
   "metadata": {
    "id": "9780d86f"
   },
   "source": [
    "### Training\n",
    "\n",
    "Training loop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cde30963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train( model, maxLen, dataLoader, device, vocabSize, epoch, optimizer_, scheduler_, criterion_ ):\n",
    "    \"\"\"\n",
    "    Training loop that takes batches from dataLoader and pushes them to device\n",
    "    to train. Will check if they're the same size of maxLen: if shorter, will\n",
    "    reduces to longest length in batch. then trains according to optimizer,\n",
    "    criterion and schedule.\n",
    "\n",
    "    Input\n",
    "        model (instance)        : model that is being trained\n",
    "        maxLen (int)            : maximum sentence length\n",
    "        dataLoader (instance)   : dataloader that batches data into tensors\n",
    "        optimizer (instance)    : Not sure what type optimizers are\n",
    "        criterion               :\n",
    "        device (str)            : gpu or cpu\n",
    "    Output\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    model.train() # Turn on the train mode\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    src_mask = model.generate_square_subsequent_mask(maxLen).to(device)\n",
    "    nbr_batches = len(dataLoader)\n",
    "    for i, batch in enumerate(dataLoader):\n",
    "        src = (batch.src).to(device); tgt = (batch.tgt).to(device)\n",
    "\n",
    "        optimizer_.zero_grad()\n",
    "        if src.size(0) != maxLen:\n",
    "            src_mask = model.generate_square_subsequent_mask(src.size(0)).to(device)\n",
    "        \n",
    "        output = model(src, src_mask)\n",
    "        loss = criterion_(output.view(-1, vocabSize), tgt.reshape(-1))\n",
    "        loss.backward()\n",
    "        torch.torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer_.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        log_interval = 5\n",
    "        if i % log_interval == 0 and i > 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            elapsed = ( time.time() - start_time ) * 1000 / log_interval\n",
    "            loss_exp = math.exp(cur_loss)\n",
    "            last_lr = scheduler_.get_last_lr()[0]\n",
    "            print(f'| epoch {epoch:3d} | {i:5d}/{nbr_batches:5d} batches | lr {last_lr:02.2f}'\n",
    "            + f'| ms/batch {elapsed:5.2f} | loss {cur_loss:5.2f} | ppl {loss_exp:8.2f}'\n",
    "                 )\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "\n",
    "# evaluation function outside of training - same as hugging face\n",
    "def evaluate(eval_model, maxLen, dataLoader, nbrSamples, device, vocabSize, criterion_):\n",
    "    \"\"\"\n",
    "    Takes a trained model, puts it in evaluation mode to see how well it\n",
    "    performs on another set of data.\n",
    "\n",
    "    Input\n",
    "        eval_model (instance)   : model to be evaluated\n",
    "        maxLen (int)            : maximum length possible/trained on\n",
    "        dataLoader (instance)   : dataloader of the dataset that is evaluate on\n",
    "        nbrSamples (int)        : Supposed to be number of samples, not sure I need\n",
    "    Output\n",
    "        loss of evaluated set\n",
    "    \"\"\"\n",
    "    eval_model.eval() # Turn on the evaluation mode\n",
    "    total_loss = 0.\n",
    "    src_mask = eval_model.generate_square_subsequent_mask(maxLen).to(device)\n",
    "    with torch.no_grad():\n",
    "        for batch in dataLoader:\n",
    "            src = (batch.src).to(device); tgt = (batch.tgt).to(device)\n",
    "            if src.size(0) != maxLen:\n",
    "                src_mask = eval_model.generate_square_subsequent_mask(\n",
    "                                                    src.size(0)).to(device)\n",
    "            output = eval_model(src, src_mask)\n",
    "            output_flat = output.view(-1, vocabSize)\n",
    "            #total_loss += len(src) * criterion_(output_flat\n",
    "            total_loss += criterion_(output_flat, tgt.reshape(-1)).item()\n",
    "    return total_loss / (nbrSamples - 1) # nbrSamples -x-> len(dataLoader)\n",
    "\n",
    "def save_model(model, tknzrFile, modelParams, tknzrParams, full=True):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "75775f0e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "executionInfo": {
     "elapsed": 174,
     "status": "error",
     "timestamp": 1628863040535,
     "user": {
      "displayName": "Jeremy Rothschild",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64",
      "userId": "12754514505135179603"
     },
     "user_tz": 240
    },
    "id": "75775f0e",
    "outputId": "dc3d67dd-9432-4ee1-dd62-e165f9adbe96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |     5/   22 batches | lr 0.50| ms/batch 878.20 | loss  9.08 | ppl  8781.81\n",
      "| epoch   1 |    10/   22 batches | lr 0.50| ms/batch 608.87 | loss  6.80 | ppl   895.98\n",
      "| epoch   1 |    15/   22 batches | lr 0.50| ms/batch 642.43 | loss  5.28 | ppl   196.77\n",
      "| epoch   1 |    20/   22 batches | lr 0.50| ms/batch 643.19 | loss  4.92 | ppl   136.40\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 15.38s | valid loss  0.20 | valid ppl     1.22\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   2 |     5/   22 batches | lr 0.47| ms/batch 873.33 | loss  5.26 | ppl   191.69\n",
      "| epoch   2 |    10/   22 batches | lr 0.47| ms/batch 663.85 | loss  4.09 | ppl    59.73\n",
      "| epoch   2 |    15/   22 batches | lr 0.47| ms/batch 691.97 | loss  4.40 | ppl    81.74\n",
      "| epoch   2 |    20/   22 batches | lr 0.47| ms/batch 699.61 | loss  4.01 | ppl    54.98\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 16.33s | valid loss  0.18 | valid ppl     1.19\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   3 |     5/   22 batches | lr 0.45| ms/batch 914.33 | loss  4.73 | ppl   112.89\n",
      "| epoch   3 |    10/   22 batches | lr 0.45| ms/batch 724.70 | loss  4.02 | ppl    55.45\n",
      "| epoch   3 |    15/   22 batches | lr 0.45| ms/batch 726.72 | loss  3.84 | ppl    46.71\n",
      "| epoch   3 |    20/   22 batches | lr 0.45| ms/batch 708.00 | loss  3.77 | ppl    43.29\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 17.06s | valid loss  0.16 | valid ppl     1.18\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   4 |     5/   22 batches | lr 0.43| ms/batch 962.53 | loss  4.36 | ppl    78.59\n",
      "| epoch   4 |    10/   22 batches | lr 0.43| ms/batch 732.82 | loss  4.04 | ppl    57.10\n",
      "| epoch   4 |    15/   22 batches | lr 0.43| ms/batch 1188.11 | loss  3.84 | ppl    46.42\n",
      "| epoch   4 |    20/   22 batches | lr 0.43| ms/batch 1568.62 | loss  3.88 | ppl    48.27\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 25.54s | valid loss  0.16 | valid ppl     1.17\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   5 |     5/   22 batches | lr 0.41| ms/batch 1917.75 | loss  4.47 | ppl    87.53\n",
      "| epoch   5 |    10/   22 batches | lr 0.41| ms/batch 1461.35 | loss  3.73 | ppl    41.74\n",
      "| epoch   5 |    15/   22 batches | lr 0.41| ms/batch 1458.88 | loss  3.68 | ppl    39.81\n",
      "| epoch   5 |    20/   22 batches | lr 0.41| ms/batch 1479.71 | loss  3.47 | ppl    32.17\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 34.68s | valid loss  0.17 | valid ppl     1.18\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   6 |     5/   22 batches | lr 0.39| ms/batch 1433.19 | loss  4.32 | ppl    74.99\n",
      "| epoch   6 |    10/   22 batches | lr 0.39| ms/batch 637.29 | loss  3.58 | ppl    35.81\n",
      "| epoch   6 |    15/   22 batches | lr 0.39| ms/batch 665.73 | loss  3.64 | ppl    38.21\n",
      "| epoch   6 |    20/   22 batches | lr 0.39| ms/batch 679.98 | loss  3.55 | ppl    34.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time: 18.62s | valid loss  0.16 | valid ppl     1.17\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   7 |     5/   22 batches | lr 0.37| ms/batch 935.11 | loss  4.23 | ppl    69.00\n",
      "| epoch   7 |    10/   22 batches | lr 0.37| ms/batch 733.12 | loss  3.40 | ppl    29.89\n",
      "| epoch   7 |    15/   22 batches | lr 0.37| ms/batch 848.74 | loss  3.69 | ppl    39.97\n",
      "| epoch   7 |    20/   22 batches | lr 0.37| ms/batch 1779.34 | loss  3.60 | ppl    36.49\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time: 25.31s | valid loss  0.17 | valid ppl     1.18\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   8 |     5/   22 batches | lr 0.35| ms/batch 2214.86 | loss  4.52 | ppl    91.73\n",
      "| epoch   8 |    10/   22 batches | lr 0.35| ms/batch 1597.86 | loss  3.44 | ppl    31.32\n",
      "| epoch   8 |    15/   22 batches | lr 0.35| ms/batch 1556.89 | loss  3.52 | ppl    33.75\n",
      "| epoch   8 |    20/   22 batches | lr 0.35| ms/batch 1502.38 | loss  3.38 | ppl    29.23\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time: 37.63s | valid loss  0.17 | valid ppl     1.18\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   9 |     5/   22 batches | lr 0.33| ms/batch 1846.66 | loss  4.16 | ppl    64.31\n",
      "| epoch   9 |    10/   22 batches | lr 0.33| ms/batch 736.64 | loss  3.41 | ppl    30.17\n",
      "| epoch   9 |    15/   22 batches | lr 0.33| ms/batch 649.37 | loss  3.11 | ppl    22.32\n",
      "| epoch   9 |    20/   22 batches | lr 0.33| ms/batch 658.24 | loss  3.52 | ppl    33.64\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time: 21.02s | valid loss  0.16 | valid ppl     1.17\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  10 |     5/   22 batches | lr 0.32| ms/batch 863.32 | loss  4.24 | ppl    69.71\n",
      "| epoch  10 |    10/   22 batches | lr 0.32| ms/batch 687.96 | loss  3.34 | ppl    28.30\n",
      "| epoch  10 |    15/   22 batches | lr 0.32| ms/batch 682.37 | loss  3.52 | ppl    33.92\n",
      "| epoch  10 |    20/   22 batches | lr 0.32| ms/batch 710.88 | loss  3.41 | ppl    30.28\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time: 17.27s | valid loss  0.15 | valid ppl     1.16\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if TRAIN:\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_model = None\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        train(model, \n",
    "              params['maxLen'],\n",
    "              trainDataLoader,\n",
    "              device,\n",
    "              params['vocabSize'],\n",
    "              epoch,\n",
    "              optimizer,\n",
    "              scheduler,\n",
    "              criterion\n",
    "             )\n",
    "        val_loss = evaluate(model,\n",
    "                            params['maxLen'],\n",
    "                            valDataLoader,\n",
    "                            len(valDataset),\n",
    "                            device,\n",
    "                            params['vocabSize'],\n",
    "                            criterion\n",
    "                           )\n",
    "        print('-' * 89)\n",
    "        timing = (time.time() - epoch_start_time)\n",
    "        exp_val = math.exp(val_loss)\n",
    "        print(f'| end of epoch {epoch:3d} | time: {timing:5.2f}s | valid loss {val_loss:5.2f} | valid ppl {exp_val:8.2f}')\n",
    "                                         # Why is math.exp so large????\n",
    "        print('-' * 89)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = model\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "    # save best model (two methods)\n",
    "    modelFull = default.MODEL_DIR + os.sep + f'{filename}_epoch{epochs}.pth'\n",
    "    modelWeights = default.MODEL_DIR + os.sep + f'{filename}_weights_epoch{epochs}.pth'\n",
    "    # approach 1: save model (class) entirely (uses pickle)\n",
    "    torch.save(model, modelFull)\n",
    "    # approach 2: save model weights\n",
    "    torch.save(model.state_dict(), modelWeights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XM5G4vD0q9TZ",
   "metadata": {
    "id": "XM5G4vD0q9TZ"
   },
   "source": [
    "### Text Generation\n",
    "\n",
    "Here I've simply taken the code Matt uses to generate text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eb6acee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "customFilename = 'arxiv_1000'\n",
    "customEpochs = 10\n",
    "modelFullPath = default.MODEL_DIR + os.sep + f'{customFilename}_epoch{customEpochs}.pth'\n",
    "modelWeightsPath = default.MODEL_DIR + os.sep + f'{customFilename}_weights_epoch{customEpochs}.pth'\n",
    "\n",
    "tknzrFile = default.TOK_DIR + os.sep + customFilename + '_' + tknzerType + '.json'\n",
    "\n",
    "# load PreTrainedTokenizerFast, for __call__. __call__ not implemented in\n",
    "# the base Tokenizer class... that sounds silly, but it is what it is\n",
    "tknzr = tkn.load_tokenizer(tknzrFile, **default.special_token_lst)\n",
    "\n",
    "if params['vocabSize'] is None: params['vocabSize'] = tknzr.vocab_size\n",
    "\n",
    "# approach 1: load model (class) entirely (uses pickle)\n",
    "modelFullLoad = torch.load(modelFullPath, map_location=device)\n",
    "\n",
    "# approach 2: load model weights, need to have some parameter or something \n",
    "#modelLoad = TransformerModel(vocabSize, emsize, nhead, nhid, nlayers, dropout).to(device)\n",
    "#modelWeightsLoad = modelLoad.load_state_dict( torch.load(modelWeightsPath) )\n",
    "\n",
    "model = modelFullLoad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "SoGylu7hq7kI",
   "metadata": {
    "id": "SoGylu7hq7kI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>  Electron  and  proton\n",
      "tensor([-0.8576, -0.3987,  6.5967,  ...,  1.4223, -0.7593,  0.6698],\n",
      "       grad_fn=<SelectBackward>)\n",
      "Electron and proton  -\n",
      "<s>  Electron  and  proton  -\n",
      "tensor([-0.4209, -0.7046,  4.4931,  ...,  1.6259, -0.8845,  0.2451],\n",
      "       grad_fn=<SelectBackward>)\n",
      "Electron and proton  -  electron\n",
      "<s>  Electron  and  proton  -  electron\n",
      "tensor([-0.8431, -1.3392,  6.0896,  ...,  2.2279, -0.2585,  0.7192],\n",
      "       grad_fn=<SelectBackward>)\n",
      "Electron and proton  -  electron  -\n",
      "<s>  Electron  and  proton  -  electron  -\n",
      "tensor([ 0.3292, -0.6793,  4.7616,  ...,  1.7054, -0.6185,  0.8677],\n",
      "       grad_fn=<SelectBackward>)\n",
      "Electron and proton  -  electron  -  electron\n",
      "<s>  Electron  and  proton  -  electron  -  electron\n",
      "tensor([-0.2461, -1.2208,  6.4529,  ...,  2.2298, -0.1769,  1.0640],\n",
      "       grad_fn=<SelectBackward>)\n",
      "Electron and proton  -  electron  -  electron  -\n",
      "<s>  Electron  and  proton  -  electron  -  electron  -\n",
      "tensor([ 1.2498, -0.6729,  4.9220,  ...,  1.6131, -0.5136,  1.2064],\n",
      "       grad_fn=<SelectBackward>)\n",
      "Electron and proton  -  electron  -  electron  -  dimensional\n",
      "<s>  Electron  and  proton  -  electron  -  electron  -  dimensional\n",
      "tensor([-0.4945, -0.3467,  7.5936,  ...,  1.7544,  0.1375,  1.2301],\n",
      "       grad_fn=<SelectBackward>)\n",
      "Electron and proton  -  electron  -  electron  -  dimensional <\\s>\n",
      "<s>  Electron  and  proton  -  electron  -  electron  -  dimensional <\\s>\n",
      "tensor([18.1700, -0.5066,  5.6502,  ...,  0.2356, -0.1671,  1.2055],\n",
      "       grad_fn=<SelectBackward>)\n",
      "Electron and proton  -  electron  -  electron  -  dimensional <\\s> <pad>\n",
      "<s>  Electron  and  proton  -  electron  -  electron  -  dimensional <\\s> <pad>\n",
      "tensor([18.6399,  0.3638,  5.7191,  ..., -0.2126, -0.1052,  1.2350],\n",
      "       grad_fn=<SelectBackward>)\n",
      "Electron and proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad>\n",
      "<s>  Electron  and  proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad>\n",
      "tensor([18.9215,  0.4246,  5.4085,  ..., -0.2399, -0.0972,  1.2123],\n",
      "       grad_fn=<SelectBackward>)\n",
      "Electron and proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad>\n",
      "<s>  Electron  and  proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad>\n",
      "tensor([18.9734,  0.5072,  5.1703,  ..., -0.2021, -0.0856,  1.2135],\n",
      "       grad_fn=<SelectBackward>)\n",
      "Electron and proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad>\n",
      "<s>  Electron  and  proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad>\n",
      "tensor([18.9492,  0.5869,  4.9801,  ..., -0.1627, -0.0627,  1.2297],\n",
      "       grad_fn=<SelectBackward>)\n",
      "Electron and proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad>\n",
      "<s>  Electron  and  proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([18.8988,  0.6593,  4.8271,  ..., -0.1414, -0.0305,  1.2527],\n",
      "       grad_fn=<SelectBackward>)\n",
      "Electron and proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<s>  Electron  and  proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([ 1.8838e+01,  7.2908e-01,  4.7083e+00,  ..., -1.3200e-01,\n",
      "         2.3259e-03,  1.2631e+00], grad_fn=<SelectBackward>)\n",
      "Electron and proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<s>  Electron  and  proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([18.7682,  0.7936,  4.6139,  ..., -0.1142,  0.0318,  1.2568],\n",
      "       grad_fn=<SelectBackward>)\n",
      "Electron and proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<s>  Electron  and  proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([18.6864,  0.8486,  4.5367,  ..., -0.0831,  0.0561,  1.2333],\n",
      "       grad_fn=<SelectBackward>)\n",
      "Electron and proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<s>  Electron  and  proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([18.5853,  0.8846,  4.4685,  ..., -0.0445,  0.0749,  1.1911],\n",
      "       grad_fn=<SelectBackward>)\n",
      "Electron and proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<s>  Electron  and  proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([ 1.8473e+01,  9.0974e-01,  4.4065e+00,  ..., -1.8227e-02,\n",
      "         9.2251e-02,  1.1507e+00], grad_fn=<SelectBackward>)\n",
      "Electron and proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<s>  Electron  and  proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([ 1.8356e+01,  9.3855e-01,  4.3516e+00,  ..., -1.6967e-02,\n",
      "         1.1742e-01,  1.1230e+00], grad_fn=<SelectBackward>)\n",
      "Electron and proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<s>  Electron  and  proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([18.2445,  0.9762,  4.3028,  ..., -0.0419,  0.1486,  1.1092],\n",
      "       grad_fn=<SelectBackward>)\n",
      "Electron and proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<s>  Electron  and  proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([18.1467,  1.0228,  4.2591,  ..., -0.0739,  0.1851,  1.1038],\n",
      "       grad_fn=<SelectBackward>)\n",
      "Electron and proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<s>  Electron  and  proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([18.0620,  1.0729,  4.2156,  ..., -0.1000,  0.2151,  1.0930],\n",
      "       grad_fn=<SelectBackward>)\n",
      "Electron and proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      " Electron  and  proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([16.2354,  1.2355,  3.9843,  ...,  0.1537,  0.1406,  0.5704],\n",
      "       grad_fn=<SelectBackward>)\n",
      "Electron and proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      " and  proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([15.5965,  2.0089,  4.1839,  ..., -0.2541, -0.2234,  0.9576],\n",
      "       grad_fn=<SelectBackward>)\n",
      "Electron and proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      " proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([15.2850,  2.0472,  4.2074,  ..., -0.4656, -0.3457,  0.9324],\n",
      "       grad_fn=<SelectBackward>)\n",
      "Electron and proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      " -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([15.7585,  1.5609,  4.8379,  ..., -0.3851,  0.3007,  0.4523],\n",
      "       grad_fn=<SelectBackward>)\n",
      "Electron and proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      " electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([14.5732,  1.7485,  4.3933,  ..., -0.1510,  0.5653,  0.8056],\n",
      "       grad_fn=<SelectBackward>)\n",
      "Electron and proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      " -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([15.4384,  1.5962,  4.5805,  ..., -0.6833,  0.4972,  0.3831],\n",
      "       grad_fn=<SelectBackward>)\n",
      "Electron and proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      " electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([14.2268,  1.7440,  4.2140,  ..., -0.3876,  0.7613,  0.7839],\n",
      "       grad_fn=<SelectBackward>)\n",
      "Electron and proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      " -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([14.8397,  1.3732,  4.3750,  ..., -1.1350,  0.6639,  0.2356],\n",
      "       grad_fn=<SelectBackward>)\n",
      "Electron and proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      " dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([13.5190,  1.3043,  3.8258,  ..., -0.9314,  1.0776,  0.7115],\n",
      "       grad_fn=<SelectBackward>)\n",
      "Electron and proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([13.2847,  1.4017,  4.4465,  ..., -1.0567,  1.0963,  0.8161],\n",
      "       grad_fn=<SelectBackward>)\n",
      "Electron and proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([12.4846,  1.0938,  4.3183,  ..., -1.1343,  0.9229,  0.4335],\n",
      "       grad_fn=<SelectBackward>)\n",
      "Electron and proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([12.4846,  1.0938,  4.3183,  ..., -1.1343,  0.9229,  0.4335],\n",
      "       grad_fn=<SelectBackward>)\n",
      "Electron and proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([12.4846,  1.0938,  4.3183,  ..., -1.1343,  0.9229,  0.4335],\n",
      "       grad_fn=<SelectBackward>)\n",
      "Electron and proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Text prompt:\n",
      " Electron and proton\n",
      "Number of tokens to generate: 35\n",
      "Generated_text:\n",
      " Electron and proton  -  electron  -  electron  -  dimensional <\\s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n"
     ]
    }
   ],
   "source": [
    "# inspect both models\n",
    "#print('model_A info...\\n', modelFullLoad)\n",
    "#print('\\nmodel_B info...\\n', modelWeightsLoad)\n",
    "\n",
    "#print('model_A == model_B:', modelFullLoad == modelWeightsLoad)\n",
    "#model = modelFullLoad\n",
    "# Text generation example\n",
    "prompt = 'Electron and proton'\n",
    "ngen = 35\n",
    "decode_style = 'greedy'\n",
    "model.to('cpu')\n",
    "generated_text = gen_some_text(model, tknzr, 'cpu', params['maxLen'], text_prompt=prompt, tokens_to_gen=ngen, vis=False,\n",
    "    decode_style=decode_style)\n",
    "print(\"Text prompt:\\n\", prompt)\n",
    "print(\"Number of tokens to generate:\", ngen)\n",
    "print(\"Generated_text:\\n\", generated_text)\n",
    "\n",
    "# TODO: alternative generation\n",
    "# currently 'greedy method'\n",
    "# see: https://huggingface.co/blog/how-to-generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbed227d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "colab_training_and_evaluation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
>>>>>>> 037989dd75c917e30623cc343965ccbb933f6c5a
