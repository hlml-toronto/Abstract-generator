{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "MZmtW9scbJ9Y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22301,
     "status": "ok",
     "timestamp": 1628862364306,
     "user": {
      "displayName": "Jeremy Rothschild",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64",
      "userId": "12754514505135179603"
     },
     "user_tz": 240
    },
    "id": "MZmtW9scbJ9Y",
    "outputId": "ccd11b5c-cfac-48ff-8fd0-ff5657730b50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in colab:  False\n",
      "Training mode:  True\n"
     ]
    }
   ],
   "source": [
    "IN_COLAB = 'google.colab' in str(get_ipython())\n",
    "TRAIN = True\n",
    "LOAD_MODEL = None\n",
    "TRAIN_TOKENIZER = True\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    %cd /content/drive/MyDrive/Github/Abstract-generator/bumbleBERT/notebooks\n",
    "    batch_size = 10 #32\n",
    "    eval_batch_size = 10 #32\n",
    "    epochs = 10  # The number of epochs\n",
    "    !pip install feedparser tokenizers transformers\n",
    "else:\n",
    "    batch_size = 32       # 3\n",
    "    val_batch_size = 32  # 3\n",
    "    epochs = 10  # The number of epochs\n",
    "\n",
    "print('Running in colab: ', IN_COLAB)\n",
    "print('Training mode: ', TRAIN)\n",
    "if LOAD_MODEL is not None:\n",
    "    print('Using previous model: ', LOAD_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "04f6ae9e",
   "metadata": {
    "executionInfo": {
     "elapsed": 343,
     "status": "ok",
     "timestamp": 1628862465466,
     "user": {
      "displayName": "Jeremy Rothschild",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64",
      "userId": "12754514505135179603"
     },
     "user_tz": 240
    },
    "id": "04f6ae9e"
   },
   "outputs": [],
   "source": [
    "import os, torch, time, math, sys, re, csv\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('..' + os.sep )\n",
    "from src import default\n",
    "\n",
    "from src.data import download as dl, tokenization as tkn, custom_dataset as cd\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from src.model.transformer_hf import TransformerModel\n",
    "from src.model.batching import CustomBatch\n",
    "from src.model.generate_text import gen_some_text\n",
    "#from src.model.train_evaluate import train, evaluate\n",
    "#from src.model.transformer import make_gpt_model # imports don't work\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904013cd",
   "metadata": {
    "id": "904013cd"
   },
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "da73442b",
   "metadata": {
    "executionInfo": {
     "elapsed": 161,
     "status": "ok",
     "timestamp": 1628862477958,
     "user": {
      "displayName": "Jeremy Rothschild",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64",
      "userId": "12754514505135179603"
     },
     "user_tz": 240
    },
    "id": "da73442b"
   },
   "outputs": [],
   "source": [
    "# ARCHITECTURE\n",
    "if LOAD_MODEL is None:\n",
    "    params = {\n",
    "                'maxLen'     : 10, # maximum sentence length\n",
    "                'vocabSize'    : None, # None if you want to let tokenizer do its thing\n",
    "                'emsize'     : 512, # embedding dimension\n",
    "                'nhid'       : 2048, # the dimension of the feedforward network model in torch.nn.TransformerEncoder\n",
    "                'nlayers'    : 12, # the number of torch.nn.TransformerEncoderLayer in torch.nn.TransformerEncoder\n",
    "                'nhead'      : 8, # the number of heads in the multiheadattention models\n",
    "                'dropout'    : 0.1 # the dropout value\n",
    "            }\n",
    "\n",
    "    # TOKENIZER\n",
    "    tknzerType = 'BPE' # type of tokenizing algorithm\n",
    "    \n",
    "else:\n",
    "    print(\"TODO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bf83d8",
   "metadata": {
    "id": "33bf83d8"
   },
   "source": [
    "### Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "67302c43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 345,
     "status": "ok",
     "timestamp": 1628862544480,
     "user": {
      "displayName": "Jeremy Rothschild",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64",
      "userId": "12754514505135179603"
     },
     "user_tz": 240
    },
    "id": "67302c43",
    "outputId": "b712b14b-c212-4ffd-cc2d-347ce05a0b92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Using arxiv_1000 for training <<\n"
     ]
    }
   ],
   "source": [
    "# download data\n",
    "nbrResults = 10**3 # number of data samples to download\n",
    "filename = f'arxiv_{nbrResults}'\n",
    "extension = '.csv'\n",
    "filepath = default.RAW_DATA_DIR + os.sep + filename + extension\n",
    "\n",
    "if not os.path.exists(filepath):\n",
    "    dl.arxiv_api( default.RAW_DATA_DIR, filepath, max_results=nbrResults ) # TODO : CHANGE SO THAT NOT CONSTANTLY LOADING DATA\n",
    "print(f'>> Using {filename} for training <<')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21983a34",
   "metadata": {
    "id": "21983a34"
   },
   "source": [
    "### Format Dataset\n",
    "\n",
    "Uses a custom dataset class, which is an iterable and callable structure that returns a sample from our dataset. Within this custom dataset, can determine all preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "015ae225",
   "metadata": {
    "executionInfo": {
     "elapsed": 1682,
     "status": "ok",
     "timestamp": 1628862556745,
     "user": {
      "displayName": "Jeremy Rothschild",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64",
      "userId": "12754514505135179603"
     },
     "user_tz": 240
    },
    "id": "015ae225"
   },
   "outputs": [],
   "source": [
    "# create dataset\n",
    "dataset = cd.ArxivDataset(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11976e8e",
   "metadata": {
    "id": "11976e8e"
   },
   "source": [
    "### Training Tokenizer\n",
    "\n",
    "Training of a custom tokenizer. Many options possible here, check the tokenizer training functions to try out various strategies. If he tokenizer for the dataset has already been trained, no need to run this again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d3a132c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3244,
     "status": "ok",
     "timestamp": 1626462968429,
     "user": {
      "displayName": "Jeremy Rothschild",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64",
      "userId": "12754514505135179603"
     },
     "user_tz": 240
    },
    "id": "d3a132c4",
    "outputId": "772cdfac-63bb-48ad-e4ea-d45eff5cb88c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning : overwriting previously save tokenizer with                        same filename ( arxiv_1000 ).\n"
     ]
    }
   ],
   "source": [
    "if ( (LOAD_MODEL is None) and TRAIN_TOKENIZER):\n",
    "    trainTokenizer: _ = tkn.train_custom_tokenizer(tknzerType, \n",
    "                                                   dataset, \n",
    "                                                   filename,\n",
    "                                                   default.TOK_DIR,\n",
    "                                                   params['vocabSize'],\n",
    "                                                   **default.special_token_lst\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3089723",
   "metadata": {
    "id": "f3089723"
   },
   "source": [
    "### Loading Tokenizer and Splitting Datasets\n",
    "\n",
    "For some reason, torch tokenizers are not callable as trained. This is confusing, but c'est la vie! Instead, need to load it from file it was saved in using the PreTrainedTokenizerFast class (__call__) implemented in here. Once that's done, you can add this tokenizer as a transform to your dataset! Useful.\n",
    "\n",
    "We also split the dataset here into training, testing and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fe434fb7",
   "metadata": {
    "executionInfo": {
     "elapsed": 626,
     "status": "ok",
     "timestamp": 1628862565146,
     "user": {
      "displayName": "Jeremy Rothschild",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64",
      "userId": "12754514505135179603"
     },
     "user_tz": 240
    },
    "id": "fe434fb7"
   },
   "outputs": [],
   "source": [
    "tknzrFile = default.TOK_DIR + os.sep + filename + '_' + tknzerType + '.json'\n",
    "\n",
    "# load PreTrainedTokenizerFast, for __call__. __call__ not implemented in\n",
    "# the base Tokenizer class... that sounds silly, but it is what it is\n",
    "tknzr = tkn.load_tokenizer(tknzrFile, **default.special_token_lst)\n",
    "\n",
    "if params['vocabSize'] is None: params['vocabSize'] = tknzr.vocab_size\n",
    "\n",
    "# set tknzr as the transform\n",
    "dataset.set_transform( tknzr )\n",
    "\n",
    "# separate dataset into train, test valid TODO : make into a function\n",
    "fracTrain, fracTest, fracVal = ( 0.7, 0.2, 0.1)\n",
    "trainTestVal = [ np.floor(fracTrain*len(dataset))\\\n",
    "                    , np.floor(fracTest*len(dataset))\\\n",
    "                    , len(dataset) - ( np.floor( fracTrain*len(dataset) ) +\n",
    "                    np.floor( fracTest*len(dataset) ) )\n",
    "                    ]\n",
    "\n",
    "trainDataset, testDataset, valDataset =\\\n",
    "        torch.utils.data.random_split(dataset,\n",
    "                                      [int(x) for x in trainTestVal],\n",
    "                                      generator=torch.Generator().manual_seed(42) \n",
    "                                     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bba4cb9",
   "metadata": {
    "id": "4bba4cb9"
   },
   "source": [
    "### Creating DataLoaders\n",
    "\n",
    "Training is done on batches, so we need a way to extract groupings of the data in the appropriate format for our transformer model.\n",
    "Note that for transformers which we are training, dataloaders outputs both src (x[:-1] and tgt ([1:]).\n",
    "The collation of batches for different transformer models we have vary. For HuggingFace it's ( maxLen x batch_size ) whereas I think that the Annotated Transformer has ( batch_size x maxLen ).\n",
    "\n",
    "NOTE : Do not use the tokenizer before the training if you use num_workers>0!\n",
    "FastTokenizer does not play nicely with forking if you use it before the forking of your data:\n",
    "https://stackoverflow.com/questions/62691279/how-to-disable-tokenizers-parallelism-true-false-warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8fc0c97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "class CustomBatch():\n",
    "    \"\"\"\n",
    "    a variant of collate_fn that pads according to the longest sequence in\n",
    "    a batch of sequences or maxLen. Unclear to me whether this is instantiated\n",
    "    at every call to dataloader or if it's instantiated along with dataloader.\n",
    "    For now, all the tensors exist on CPU and are later pushed to the GPU. Needs\n",
    "    potentially to be changed.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, dim=0, maxLenModel=100, padValue=0, stackDim=1):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            data (dataset)      : a batch of dataset.\n",
    "            dim (int)           : the dimension to be padded (dimension of time in sequences)\n",
    "            maxLenModel (int)   : maixmum length of sentence\n",
    "            padValue (int)      : the value for padding.\n",
    "            stackDim (int)      : dimension along which to stack the data in tensor.\n",
    "                                    1 for huggingface, 0 for annotated transformer\n",
    "        \"\"\"\n",
    "        self.dim = dim; self.padValue = padValue\n",
    "\n",
    "        max_len_seq = np.max( [ x.shape[self.dim] for x in data ] )\n",
    "        self.maxLen = np.min( [max_len_seq, maxLenModel] )\n",
    "        \n",
    "        # pad according to max_len\n",
    "        batch = [self.pad_tensor(x[:self.maxLen]) for x in data ]\n",
    "        #pad_mask = [  ]\n",
    "        # stack all, change to dim = 0 for annotated transformer?\n",
    "        self.src = (torch.stack([x[:-1] for x in batch], dim=stackDim)).long()\n",
    "        self.tgt = (torch.stack([x[1:] for x in batch], dim=stackDim)).long()\n",
    "        #self.pad_mask = (torch.stack([x[1:] for x in batch], dim=stackDim)).long()\n",
    "        #ys = torch.LongTensor(map(lambda x: x[1], batch))\n",
    "\n",
    "    def pad_tensor(self, vec):\n",
    "        \"\"\"\n",
    "        padding a tensor which represents a batch\n",
    "\n",
    "        Input:\n",
    "            vec : tensor to pad\n",
    "\n",
    "        Output:\n",
    "            a new tensor padded to 'pad' in dimension 'dim'\n",
    "        \"\"\"\n",
    "        padSize = list(vec.shape)\n",
    "        padSize[self.dim] = self.maxLen - vec.size(self.dim)\n",
    "        return torch.cat([vec, self.padValue*torch.ones(*padSize)], dim=self.dim)\n",
    "\n",
    "    def pin_memory(self):\n",
    "        self.src = self.src.pin_memory()\n",
    "        self.tgt = self.tgt.pin_memory()\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c11048fc",
   "metadata": {
    "executionInfo": {
     "elapsed": 151,
     "status": "ok",
     "timestamp": 1628862600927,
     "user": {
      "displayName": "Jeremy Rothschild",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64",
      "userId": "12754514505135179603"
     },
     "user_tz": 240
    },
    "id": "c11048fc"
   },
   "outputs": [],
   "source": [
    "# create dataloaders\n",
    "# uses collate function to transform batch to correct dimensions\n",
    "def collate_wrapper(batch):\n",
    "    return CustomBatch(batch,\n",
    "                       dim = 0,\n",
    "                       maxLenModel = params['maxLen'],\n",
    "                       padValue = tknzr.get_vocab()[\"<pad>\"]\n",
    "                      )\n",
    "\n",
    "# dataloader for training\n",
    "trainDataLoader = DataLoader(trainDataset,\n",
    "                             batch_size = batch_size,\n",
    "                             shuffle = True,\n",
    "                             num_workers = 2,\n",
    "                             collate_fn = collate_wrapper,\n",
    "                             pin_memory = True\n",
    "                             )\n",
    "# dataloader for validation\n",
    "valDataLoader = DataLoader(valDataset, \n",
    "                           batch_size = val_batch_size,\n",
    "                           shuffle = True,\n",
    "                           num_workers = 2,\n",
    "                           collate_fn = collate_wrapper,\n",
    "                           pin_memory = True,\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3955854",
   "metadata": {
    "id": "e3955854"
   },
   "source": [
    "### Selecting model\n",
    "\n",
    "Here we choose which model we shall use for training. For now, I've selected the black box Transformer from HuggingFace because the collate_fn I've written gives the correct input size force it... however this can easily be changed! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6de7d252",
   "metadata": {
    "executionInfo": {
     "elapsed": 870,
     "status": "ok",
     "timestamp": 1628862621722,
     "user": {
      "displayName": "Jeremy Rothschild",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64",
      "userId": "12754514505135179603"
     },
     "user_tz": 240
    },
    "id": "6de7d252"
   },
   "outputs": [],
   "source": [
    "# transformer from huggingface\n",
    "# TODO : Change to the Annotated Transformer if I want\n",
    "model = TransformerModel(params['vocabSize'],\n",
    "                         params['emsize'], \n",
    "                         params['nhead'], \n",
    "                         params['nhid'], \n",
    "                         params['nlayers'], \n",
    "                         params['dropout']\n",
    "                        ).to(device)\n",
    "\n",
    "# criterion\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "# learning rate Matt used with Adam is 0.5\n",
    "paramsAdam  = [{'params' : model.parameters(),\n",
    "                'lr'     : 0.5, 'betas' : (0.9, 0.999),\n",
    "                'eps'    : 1e-08, 'weight_decay' : 0.0\n",
    "               }\n",
    "              ]\n",
    "paramsAdamW = [{'params' : model.parameters(),\n",
    "                'lr'     : 5e-5,\n",
    "                'betas'  : (0.9, 0.999),\n",
    "                'eps'    : 1e-08,\n",
    "                'weight_decay' : 0.0\n",
    "               }\n",
    "              ]\n",
    "paramsSGD   = [{'params'    : model.parameters(),\n",
    "                'lr'        : 0.5,\n",
    "                'momentum'  : 0.0,\n",
    "                'dampening' : 0.0,\n",
    "                'weight_decay' : 0.0\n",
    "               }\n",
    "              ]\n",
    "\n",
    "optimizer = torch.optim.SGD( paramsSGD )\n",
    "#optimizer = torch.optim.Adam( paramsAdam )\n",
    "#optimizer = torch.optim.AdamW( paramsAdamW )\n",
    "\n",
    "# scheduler\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9780d86f",
   "metadata": {
    "id": "9780d86f"
   },
   "source": [
    "### Training\n",
    "\n",
    "Training loop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cde30963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train( model, maxLen, dataLoader, device, vocabSize, epoch, optimizer_, scheduler_, criterion_ ):\n",
    "    \"\"\"\n",
    "    Training loop that takes batches from dataLoader and pushes them to device\n",
    "    to train. Will check if they're the same size of maxLen: if shorter, will\n",
    "    reduces to longest length in batch. then trains according to optimizer,\n",
    "    criterion and schedule.\n",
    "\n",
    "    Input\n",
    "        model (instance)        : model that is being trained\n",
    "        maxLen (int)            : maximum sentence length\n",
    "        dataLoader (instance)   : dataloader that batches data into tensors\n",
    "        optimizer (instance)    : Not sure what type optimizers are\n",
    "        criterion               :\n",
    "        device (str)            : gpu or cpu\n",
    "    Output\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    model.train() # Turn on the train mode\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    src_mask = model.generate_square_subsequent_mask(maxLen).to(device)\n",
    "    nbr_batches = len(dataLoader)\n",
    "    for i, batch in enumerate(dataLoader):\n",
    "        src = (batch.src).to(device); tgt = (batch.tgt).to(device)\n",
    "\n",
    "        optimizer_.zero_grad()\n",
    "        if src.size(0) != maxLen:\n",
    "            src_mask = model.generate_square_subsequent_mask(src.size(0)).to(device)\n",
    "        \n",
    "        output = model(src, src_mask)\n",
    "        loss = criterion_(output.view(-1, vocabSize), tgt.reshape(-1))\n",
    "        loss.backward()\n",
    "        torch.torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer_.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        log_interval = 5\n",
    "        if i % log_interval == 0 and i > 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            elapsed = ( time.time() - start_time ) * 1000 / log_interval\n",
    "            loss_exp = math.exp(cur_loss)\n",
    "            last_lr = scheduler_.get_last_lr()[0]\n",
    "            print(f'| epoch {epoch:3d} | {i:5d}/{nbr_batches:5d} batches | lr {last_lr:02.2f}'\n",
    "            + f'| ms/batch {elapsed:5.2f} | loss {cur_loss:5.2f} | ppl {loss_exp:8.2f}'\n",
    "                 )\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "\n",
    "# evaluation function outside of training - same as hugging face\n",
    "def evaluate(eval_model, maxLen, dataLoader, nbrSamples, device, vocabSize, criterion_):\n",
    "    \"\"\"\n",
    "    Takes a trained model, puts it in evaluation mode to see how well it\n",
    "    performs on another set of data.\n",
    "\n",
    "    Input\n",
    "        eval_model (instance)   : model to be evaluated\n",
    "        maxLen (int)            : maximum length possible/trained on\n",
    "        dataLoader (instance)   : dataloader of the dataset that is evaluate on\n",
    "        nbrSamples (int)        : Supposed to be number of samples, not sure I need\n",
    "    Output\n",
    "        loss of evaluated set\n",
    "    \"\"\"\n",
    "    eval_model.eval() # Turn on the evaluation mode\n",
    "    total_loss = 0.\n",
    "    src_mask = eval_model.generate_square_subsequent_mask(maxLen).to(device)\n",
    "    with torch.no_grad():\n",
    "        for batch in dataLoader:\n",
    "            src = (batch.src).to(device); tgt = (batch.tgt).to(device)\n",
    "            if src.size(0) != maxLen:\n",
    "                src_mask = eval_model.generate_square_subsequent_mask(\n",
    "                                                    src.size(0)).to(device)\n",
    "            output = eval_model(src, src_mask)\n",
    "            output_flat = output.view(-1, vocabSize)\n",
    "            #total_loss += len(src) * criterion_(output_flat\n",
    "            total_loss += criterion_(output_flat, tgt.reshape(-1)).item()\n",
    "    return total_loss / (nbrSamples - 1) # nbrSamples -x-> len(dataLoader)\n",
    "\n",
    "def save_model(model, tknzrFile, modelParams, tknzrParams, full=True):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3adc3e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [3731, 4652, 2412, 1717,  749,  289, 1691, 2054,  988, 4764, 2799, 4988,\n",
      "          802,  611,  122, 5378, 2097,  623, 2533,  897, 1357,  122, 2109,  122,\n",
      "         3352,  122, 3603, 1509,  122, 4897,  658, 2795],\n",
      "        [ 134, 1060,  658,  844,  116,  988,  122,  557,  116,  134,  116, 4429,\n",
      "         3958,  116,  107,  139,  116,  775,  122, 1435, 2886,  107,  116,  107,\n",
      "          199,  107, 2712, 1619,  456, 1397,  471, 4170],\n",
      "        [ 429, 1364,  139, 1546, 1047, 3952,  107,  678,  647,  122,  145,    2,\n",
      "          139, 1706,  641, 4076,  646,  107, 1263,  107, 4492,  111,  145,  262,\n",
      "          164,  262,  116,  116,  139,  134,  110, 4165],\n",
      "        [ 107,  425,  315, 1500, 2927, 5415, 1996,  313,  407, 2354, 1936,    0,\n",
      "         5213,  201, 1862, 5362,  139,  111,  110,  122,  110, 2082,  575,  421,\n",
      "         4058,  440,  134,  876, 1045,  122,  134, 2542],\n",
      "        [2367,  122,    2,  965,  107,  199,  502,    2,  259,    2,  110,    0,\n",
      "         2798,  240,  212,  110,  293, 5128,  952,  620,  259,  110,  111,  110,\n",
      "          195,  180, 2372,  139, 1416,  107,  293, 5368],\n",
      "        [ 848,  914,    0,  201, 2894, 5317,  110,    0,  107,    0,  127,    0,\n",
      "          195, 1966,  979,  134, 1702,  246, 2777, 5085,  107,  127,  107,  145,\n",
      "         4335,  293, 2106,  111,  110,  122,  107,  315],\n",
      "        [ 647,  110,    0,  425, 4949,  139, 5178,    0,  275,    0,  111,    0,\n",
      "         3627,  107,  107,  293,  110,  134,  199,  199,  111, 5337,  262,  259,\n",
      "          134,  107,  122,  110, 1390,  330, 1232,    2],\n",
      "        [ 407, 4512,    0,  702,  110, 5084,  122,    0,  111,    0,  545,    0,\n",
      "         4979, 2833, 4625,  107,  647, 1799, 3708,  349, 1645, 5023,  545,  107,\n",
      "          111,  718,  107,  759,  977,  325,  917,    0]])\n",
      "tensor([[3731, 4652, 2412, 1717,  749,  289, 1691, 2054,  988, 4764, 2799, 4988,\n",
      "          802,  611,  122, 5378, 2097,  623, 2533,  897, 1357,  122, 2109,  122,\n",
      "         3352,  122, 3603, 1509,  122, 4897,  658, 2795],\n",
      "        [ 134, 1060,  658,  844,  116,  988,  122,  557,  116,  134,  116, 4429,\n",
      "         3958,  116,  107,  139,  116,  775,  122, 1435, 2886,  107,  116,  107,\n",
      "          199,  107, 2712, 1619,  456, 1397,  471, 4170],\n",
      "        [ 429, 1364,  139, 1546, 1047, 3952,  107,  678,  647,  122,  145,    2,\n",
      "          139, 1706,  641, 4076,  646,  107, 1263,  107, 4492,  111,  145,  262,\n",
      "          164,  262,  116,  116,  139,  134,  110, 4165],\n",
      "        [ 107,  425,  315, 1500, 2927, 5415, 1996,  313,  407, 2354, 1936,    0,\n",
      "         5213,  201, 1862, 5362,  139,  111,  110,  122,  110, 2082,  575,  421,\n",
      "         4058,  440,  134,  876, 1045,  122,  134, 2542],\n",
      "        [2367,  122,    2,  965,  107,  199,  502,    2,  259,    2,  110,    0,\n",
      "         2798,  240,  212,  110,  293, 5128,  952,  620,  259,  110,  111,  110,\n",
      "          195,  180, 2372,  139, 1416,  107,  293, 5368],\n",
      "        [ 848,  914,    0,  201, 2894, 5317,  110,    0,  107,    0,  127,    0,\n",
      "          195, 1966,  979,  134, 1702,  246, 2777, 5085,  107,  127,  107,  145,\n",
      "         4335,  293, 2106,  111,  110,  122,  107,  315],\n",
      "        [ 647,  110,    0,  425, 4949,  139, 5178,    0,  275,    0,  111,    0,\n",
      "         3627,  107,  107,  293,  110,  134,  199,  199,  111, 5337,  262,  259,\n",
      "          134,  107,  122,  110, 1390,  330, 1232,    2],\n",
      "        [ 407, 4512,    0,  702,  110, 5084,  122,    0,  111,    0,  545,    0,\n",
      "         4979, 2833, 4625,  107,  647, 1799, 3708,  349, 1645, 5023,  545,  107,\n",
      "          111,  718,  107,  759,  977,  325,  917,    0],\n",
      "        [ 111,  999,    0,  425, 1201,    2,  548,    0,  360,    0,  425,    0,\n",
      "          116,  107,  641,  444,  407,  116,  107, 1719,  107,  253,  110,  275,\n",
      "          107, 3365, 1913,  116, 2002,  308,  111,    0]])\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(trainDataLoader):\n",
    "    if i < 1:\n",
    "        print(batch.src)\n",
    "        print(batch.tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75775f0e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "executionInfo": {
     "elapsed": 174,
     "status": "error",
     "timestamp": 1628863040535,
     "user": {
      "displayName": "Jeremy Rothschild",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64",
      "userId": "12754514505135179603"
     },
     "user_tz": 240
    },
    "id": "75775f0e",
    "outputId": "dc3d67dd-9432-4ee1-dd62-e165f9adbe96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "| epoch   1 |     5/   22 batches | lr 0.50| ms/batch 480.48 | loss 10.06 | ppl 23431.06\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "| epoch   1 |    10/   22 batches | lr 0.50| ms/batch 341.34 | loss  7.70 | ppl  2207.77\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "| epoch   1 |    15/   22 batches | lr 0.50| ms/batch 347.03 | loss  7.29 | ppl  1459.78\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "| epoch   1 |    20/   22 batches | lr 0.50| ms/batch 344.69 | loss  7.14 | ppl  1260.26\n",
      "9\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time:  8.51s | valid loss  0.29 | valid ppl     1.33\n",
      "-----------------------------------------------------------------------------------------\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "| epoch   2 |     5/   22 batches | lr 0.47| ms/batch 496.05 | loss  8.27 | ppl  3902.16\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "| epoch   2 |    10/   22 batches | lr 0.47| ms/batch 361.53 | loss  6.93 | ppl  1018.27\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "| epoch   2 |    15/   22 batches | lr 0.47| ms/batch 340.61 | loss  7.04 | ppl  1136.56\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "| epoch   2 |    20/   22 batches | lr 0.47| ms/batch 340.12 | loss  6.84 | ppl   936.76\n",
      "9\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time:  8.66s | valid loss  0.28 | valid ppl     1.32\n",
      "-----------------------------------------------------------------------------------------\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "| epoch   3 |     5/   22 batches | lr 0.45| ms/batch 466.31 | loss  8.02 | ppl  3038.24\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "| epoch   3 |    10/   22 batches | lr 0.45| ms/batch 340.53 | loss  6.62 | ppl   749.29\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "| epoch   3 |    15/   22 batches | lr 0.45| ms/batch 328.72 | loss  6.58 | ppl   722.57\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "| epoch   3 |    20/   22 batches | lr 0.45| ms/batch 338.00 | loss  6.69 | ppl   807.32\n",
      "9\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time:  8.35s | valid loss  0.28 | valid ppl     1.32\n",
      "-----------------------------------------------------------------------------------------\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "| epoch   4 |     5/   22 batches | lr 0.43| ms/batch 481.13 | loss  7.69 | ppl  2192.82\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "| epoch   4 |    10/   22 batches | lr 0.43| ms/batch 334.99 | loss  6.62 | ppl   751.57\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "| epoch   4 |    15/   22 batches | lr 0.43| ms/batch 357.96 | loss  6.48 | ppl   650.02\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "| epoch   4 |    20/   22 batches | lr 0.43| ms/batch 341.39 | loss  6.24 | ppl   513.00\n",
      "9\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time:  8.55s | valid loss  0.28 | valid ppl     1.32\n",
      "-----------------------------------------------------------------------------------------\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "| epoch   5 |     5/   22 batches | lr 0.41| ms/batch 520.35 | loss  7.57 | ppl  1938.37\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "| epoch   5 |    10/   22 batches | lr 0.41| ms/batch 353.49 | loss  6.24 | ppl   512.22\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "| epoch   5 |    15/   22 batches | lr 0.41| ms/batch 352.29 | loss  6.26 | ppl   521.71\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "| epoch   5 |    20/   22 batches | lr 0.41| ms/batch 354.40 | loss  6.21 | ppl   495.43\n",
      "9\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time:  8.91s | valid loss  0.26 | valid ppl     1.29\n",
      "-----------------------------------------------------------------------------------------\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "| epoch   6 |     5/   22 batches | lr 0.39| ms/batch 500.83 | loss  7.14 | ppl  1267.35\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "| epoch   6 |    10/   22 batches | lr 0.39| ms/batch 353.24 | loss  6.27 | ppl   531.02\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "| epoch   6 |    15/   22 batches | lr 0.39| ms/batch 358.38 | loss  6.16 | ppl   474.98\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "| epoch   6 |    20/   22 batches | lr 0.39| ms/batch 371.95 | loss  6.09 | ppl   442.95\n",
      "9\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time:  8.89s | valid loss  0.26 | valid ppl     1.29\n",
      "-----------------------------------------------------------------------------------------\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "| epoch   7 |     5/   22 batches | lr 0.37| ms/batch 520.53 | loss  7.11 | ppl  1221.54\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "| epoch   7 |    10/   22 batches | lr 0.37| ms/batch 371.60 | loss  5.91 | ppl   369.49\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "| epoch   7 |    15/   22 batches | lr 0.37| ms/batch 368.70 | loss  5.91 | ppl   368.92\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "| epoch   7 |    20/   22 batches | lr 0.37| ms/batch 384.10 | loss  5.95 | ppl   382.88\n",
      "9\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time:  9.22s | valid loss  0.25 | valid ppl     1.28\n",
      "-----------------------------------------------------------------------------------------\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "| epoch   8 |     5/   22 batches | lr 0.35| ms/batch 526.49 | loss  6.84 | ppl   936.92\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "| epoch   8 |    10/   22 batches | lr 0.35| ms/batch 444.89 | loss  5.73 | ppl   307.75\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "| epoch   8 |    15/   22 batches | lr 0.35| ms/batch 659.22 | loss  5.82 | ppl   335.39\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "| epoch   8 |    20/   22 batches | lr 0.35| ms/batch 862.87 | loss  5.84 | ppl   343.00\n",
      "9\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time: 14.79s | valid loss  0.25 | valid ppl     1.29\n",
      "-----------------------------------------------------------------------------------------\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "| epoch   9 |     5/   22 batches | lr 0.33| ms/batch 1101.34 | loss  6.65 | ppl   771.84\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "| epoch   9 |    10/   22 batches | lr 0.33| ms/batch 817.71 | loss  5.61 | ppl   272.26\n",
      "9\n",
      "9\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "if TRAIN:\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_model = None\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        train(model, \n",
    "              params['maxLen'],\n",
    "              trainDataLoader,\n",
    "              device,\n",
    "              params['vocabSize'],\n",
    "              epoch,\n",
    "              optimizer,\n",
    "              scheduler,\n",
    "              criterion\n",
    "             )\n",
    "        val_loss = evaluate(model,\n",
    "                            params['maxLen'],\n",
    "                            valDataLoader,\n",
    "                            len(valDataset),\n",
    "                            device,\n",
    "                            params['vocabSize'],\n",
    "                            criterion\n",
    "                           )\n",
    "        print('-' * 89)\n",
    "        timing = (time.time() - epoch_start_time)\n",
    "        exp_val = math.exp(val_loss)\n",
    "        print(f'| end of epoch {epoch:3d} | time: {timing:5.2f}s | valid loss {val_loss:5.2f} | valid ppl {exp_val:8.2f}')\n",
    "                                         # Why is math.exp so large????\n",
    "        print('-' * 89)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = model\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "    # save best model (two methods)\n",
    "    modelFull = default.MODEL_DIR + os.sep + f'{filename}_epoch{epochs}.pth'\n",
    "    modelWeights = default.MODEL_DIR + os.sep + f'{filename}_weights_epoch{epochs}.pth'\n",
    "    # approach 1: save model (class) entirely (uses pickle)\n",
    "    torch.save(model, modelFull)\n",
    "    # approach 2: save model weights\n",
    "    torch.save(model.state_dict(), modelWeights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XM5G4vD0q9TZ",
   "metadata": {
    "id": "XM5G4vD0q9TZ"
   },
   "source": [
    "### Text Generation\n",
    "\n",
    "Here I've simply taken the code Matt uses to generate text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eb6acee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "customFilename = 'arxiv_1000'\n",
    "customEpochs = 10\n",
    "modelFullPath = default.MODEL_DIR + os.sep + f'{customFilename}_epoch{customEpochs}.pth'\n",
    "modelWeightsPath = default.MODEL_DIR + os.sep + f'{customFilename}_weights_epoch{customEpochs}.pth'\n",
    "\n",
    "tknzrFile = default.TOK_DIR + os.sep + customFilename + '_' + tknzerType + '.json'\n",
    "\n",
    "# load PreTrainedTokenizerFast, for __call__. __call__ not implemented in\n",
    "# the base Tokenizer class... that sounds silly, but it is what it is\n",
    "tknzr = tkn.load_tokenizer(tknzrFile, **default.special_token_lst)\n",
    "\n",
    "if params['vocabSize'] is None: params['vocabSize'] = tknzr.vocab_size\n",
    "\n",
    "# approach 1: load model (class) entirely (uses pickle)\n",
    "modelFullLoad = torch.load(modelFullPath, map_location=device)\n",
    "\n",
    "# approach 2: load model weights, need to have some parameter or something \n",
    "#modelLoad = TransformerModel(vocabSize, emsize, nhead, nhid, nlayers, dropout).to(device)\n",
    "#modelWeightsLoad = modelLoad.load_state_dict( torch.load(modelWeightsPath) )\n",
    "\n",
    "model = modelFullLoad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "SoGylu7hq7kI",
   "metadata": {
    "id": "SoGylu7hq7kI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>  Electron\n",
      "tensor([ 146.7562,  -16.5392, -102.9582,  ...,  -18.1525,   25.8854,\n",
      "          -7.8421], grad_fn=<SelectBackward>)\n",
      "Electron <pad>\n",
      "<s>  Electron <pad>\n",
      "tensor([ 146.7562,  -16.5392, -102.9582,  ...,  -18.1525,   25.8854,\n",
      "          -7.8421], grad_fn=<SelectBackward>)\n",
      "Electron <pad> <pad>\n",
      "<s>  Electron <pad> <pad>\n",
      "tensor([ 146.7562,  -16.5392, -102.9582,  ...,  -18.1525,   25.8854,\n",
      "          -7.8421], grad_fn=<SelectBackward>)\n",
      "Electron <pad> <pad> <pad>\n",
      "<s>  Electron <pad> <pad> <pad>\n",
      "tensor([ 146.7562,  -16.5392, -102.9582,  ...,  -18.1525,   25.8854,\n",
      "          -7.8421], grad_fn=<SelectBackward>)\n",
      "Electron <pad> <pad> <pad> <pad>\n",
      "<s>  Electron <pad> <pad> <pad> <pad>\n",
      "tensor([ 146.7562,  -16.5392, -102.9582,  ...,  -18.1525,   25.8854,\n",
      "          -7.8421], grad_fn=<SelectBackward>)\n",
      "Electron <pad> <pad> <pad> <pad> <pad>\n",
      "<s>  Electron <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([ 146.7562,  -16.5392, -102.9582,  ...,  -18.1525,   25.8854,\n",
      "          -7.8421], grad_fn=<SelectBackward>)\n",
      "Electron <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<s>  Electron <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([ 146.7562,  -16.5392, -102.9582,  ...,  -18.1525,   25.8854,\n",
      "          -7.8421], grad_fn=<SelectBackward>)\n",
      "Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<s>  Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([ 146.7562,  -16.5392, -102.9582,  ...,  -18.1525,   25.8854,\n",
      "          -7.8421], grad_fn=<SelectBackward>)\n",
      "Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<s>  Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([ 146.7562,  -16.5392, -102.9582,  ...,  -18.1525,   25.8854,\n",
      "          -7.8421], grad_fn=<SelectBackward>)\n",
      "Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<s>  Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([ 146.7562,  -16.5392, -102.9582,  ...,  -18.1525,   25.8854,\n",
      "          -7.8421], grad_fn=<SelectBackward>)\n",
      "Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<s>  Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([ 146.7562,  -16.5392, -102.9582,  ...,  -18.1525,   25.8854,\n",
      "          -7.8421], grad_fn=<SelectBackward>)\n",
      "Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<s>  Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([ 146.7562,  -16.5392, -102.9582,  ...,  -18.1525,   25.8854,\n",
      "          -7.8421], grad_fn=<SelectBackward>)\n",
      "Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<s>  Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([ 146.7562,  -16.5392, -102.9582,  ...,  -18.1525,   25.8854,\n",
      "          -7.8421], grad_fn=<SelectBackward>)\n",
      "Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<s>  Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([ 146.7562,  -16.5392, -102.9582,  ...,  -18.1525,   25.8854,\n",
      "          -7.8421], grad_fn=<SelectBackward>)\n",
      "Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<s>  Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([ 146.7562,  -16.5392, -102.9582,  ...,  -18.1525,   25.8854,\n",
      "          -7.8421], grad_fn=<SelectBackward>)\n",
      "Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<s>  Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([ 146.7562,  -16.5392, -102.9582,  ...,  -18.1525,   25.8854,\n",
      "          -7.8421], grad_fn=<SelectBackward>)\n",
      "Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<s>  Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([ 146.7562,  -16.5392, -102.9582,  ...,  -18.1525,   25.8854,\n",
      "          -7.8421], grad_fn=<SelectBackward>)\n",
      "Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<s>  Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([ 146.7562,  -16.5392, -102.9582,  ...,  -18.1525,   25.8854,\n",
      "          -7.8421], grad_fn=<SelectBackward>)\n",
      "Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<s>  Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([ 146.7562,  -16.5392, -102.9582,  ...,  -18.1525,   25.8854,\n",
      "          -7.8421], grad_fn=<SelectBackward>)\n",
      "Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<s>  Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([ 146.7562,  -16.5392, -102.9582,  ...,  -18.1525,   25.8854,\n",
      "          -7.8421], grad_fn=<SelectBackward>)\n",
      "Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<s>  Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([ 146.7562,  -16.5392, -102.9582,  ...,  -18.1525,   25.8854,\n",
      "          -7.8421], grad_fn=<SelectBackward>)\n",
      "Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<s>  Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([ 146.7562,  -16.5392, -102.9582,  ...,  -18.1525,   25.8854,\n",
      "          -7.8421], grad_fn=<SelectBackward>)\n",
      "Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<s>  Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([ 146.7562,  -16.5392, -102.9582,  ...,  -18.1525,   25.8854,\n",
      "          -7.8421], grad_fn=<SelectBackward>)\n",
      "Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<s>  Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([ 146.7562,  -16.5392, -102.9582,  ...,  -18.1525,   25.8854,\n",
      "          -7.8421], grad_fn=<SelectBackward>)\n",
      "Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<s>  Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([ 146.7562,  -16.5392, -102.9582,  ...,  -18.1525,   25.8854,\n",
      "          -7.8421], grad_fn=<SelectBackward>)\n",
      "Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<s>  Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([ 146.7562,  -16.5392, -102.9582,  ...,  -18.1525,   25.8854,\n",
      "          -7.8421], grad_fn=<SelectBackward>)\n",
      "Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<s>  Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([ 146.7562,  -16.5392, -102.9582,  ...,  -18.1525,   25.8854,\n",
      "          -7.8421], grad_fn=<SelectBackward>)\n",
      "Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<s>  Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([ 146.7562,  -16.5392, -102.9582,  ...,  -18.1525,   25.8854,\n",
      "          -7.8421], grad_fn=<SelectBackward>)\n",
      "Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<s>  Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([ 146.7562,  -16.5392, -102.9582,  ...,  -18.1525,   25.8854,\n",
      "          -7.8421], grad_fn=<SelectBackward>)\n",
      "Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<s>  Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([ 146.7562,  -16.5392, -102.9582,  ...,  -18.1525,   25.8854,\n",
      "          -7.8421], grad_fn=<SelectBackward>)\n",
      "Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<s>  Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([ 146.7562,  -16.5392, -102.9582,  ...,  -18.1525,   25.8854,\n",
      "          -7.8421], grad_fn=<SelectBackward>)\n",
      "Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<s>  Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([ 146.7562,  -16.5392, -102.9582,  ...,  -18.1525,   25.8854,\n",
      "          -7.8421], grad_fn=<SelectBackward>)\n",
      "Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<s>  Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([ 146.7562,  -16.5392, -102.9582,  ...,  -18.1525,   25.8854,\n",
      "          -7.8421], grad_fn=<SelectBackward>)\n",
      "Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<s>  Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([ 146.7562,  -16.5392, -102.9582,  ...,  -18.1525,   25.8854,\n",
      "          -7.8421], grad_fn=<SelectBackward>)\n",
      "Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      " Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 146.7562,  -16.5392, -102.9582,  ...,  -18.1525,   25.8854,\n",
      "          -7.8421], grad_fn=<SelectBackward>)\n",
      "Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Text prompt:\n",
      " Electron\n",
      "Number of tokens to generate: 35\n",
      "Generated_text:\n",
      " Electron <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n"
     ]
    }
   ],
   "source": [
    "# inspect both models\n",
    "#print('model_A info...\\n', modelFullLoad)\n",
    "#print('\\nmodel_B info...\\n', modelWeightsLoad)\n",
    "\n",
    "#print('model_A == model_B:', modelFullLoad == modelWeightsLoad)\n",
    "#model = modelFullLoad\n",
    "# Text generation example\n",
    "prompt = 'Electron'\n",
    "ngen = 35\n",
    "decode_style = 'greedy'\n",
    "model.to('cpu')\n",
    "generated_text = gen_some_text(model, tknzr, 'cpu', params['maxLen'], text_prompt=prompt, tokens_to_gen=ngen, vis=False,\n",
    "    decode_style=decode_style)\n",
    "print(\"Text prompt:\\n\", prompt)\n",
    "print(\"Number of tokens to generate:\", ngen)\n",
    "print(\"Generated_text:\\n\", generated_text)\n",
    "\n",
    "# TODO: alternative generation\n",
    "# currently 'greedy method'\n",
    "# see: https://huggingface.co/blog/how-to-generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbed227d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "colab_training_and_evaluation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
