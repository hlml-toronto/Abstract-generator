{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2695,"status":"ok","timestamp":1640268008523,"user":{"displayName":"Jeremy Rothschild","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64","userId":"12754514505135179603"},"user_tz":300},"id":"MZmtW9scbJ9Y","outputId":"a03dc798-66cb-434c-f5d5-5cb4044299dd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Github/Abstract-generator/notebooks\n"]}],"source":["IN_COLAB = 'google.colab' in str(get_ipython())\n","\n","if IN_COLAB:\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=True)\n","    %cd /content/drive/MyDrive/Github/Abstract-generator/notebooks"],"id":"MZmtW9scbJ9Y"},{"cell_type":"code","source":["%%capture\n","if IN_COLAB:\n","  !pip install feedparser tokenizers transformers scipy==1.7.1;"],"metadata":{"id":"2p8t9jjUlx_O","executionInfo":{"status":"ok","timestamp":1640268023343,"user_tz":300,"elapsed":11140,"user":{"displayName":"Jeremy Rothschild","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64","userId":"12754514505135179603"}}},"id":"2p8t9jjUlx_O","execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":308,"status":"ok","timestamp":1640268601704,"user":{"displayName":"Jeremy Rothschild","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64","userId":"12754514505135179603"},"user_tz":300},"id":"04f6ae9e","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1adbd168-ed50-4bb5-c456-1ff167dc0ca5"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Github/Abstract-generator\n"]}],"source":["import os, torch, time, math, sys, re, csv\n","import numpy as np\n","\n","PACKAGE_ROOT = os.path.dirname(os.path.abspath(''))\n","print(PACKAGE_ROOT)\n","sys.path.append(PACKAGE_ROOT)\n","\n","from src import settings\n","import src.data.dataset_class as dsc\n","import src.data.dataloader_class as dlc\n","\n","from src.model.transformer_torch import TransformerModel\n","from src.model.generate_text import gen_some_text\n","\n","from src.model.train_evaluate import train_version_jeremy as train\n","from src.model.train_evaluate import evaluate_version_jeremy as evaluate\n","\n","#from src.model.transformer import make_gpt_model # imports don't work\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"id":"04f6ae9e"},{"cell_type":"markdown","metadata":{"id":"904013cd"},"source":["### Parameters"],"id":"904013cd"},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":243,"status":"ok","timestamp":1640268120299,"user":{"displayName":"Jeremy Rothschild","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64","userId":"12754514505135179603"},"user_tz":300},"id":"da73442b"},"outputs":[],"source":["# ARCHITECTURE\n","max_len_sentence     = 40 # maximum sentence length\n","vocab_size  = None # None if you want to let tokenizer do its thing\n","emsize     = 512 # embedding dimension\n","nhid       = 2048 # the dimension of the feedforward network model in torch.nn.TransformerEncoder\n","nlayers    = 12 # the number of torch.nn.TransformerEncoderLayer in torch.nn.TransformerEncoder\n","nhead      = 8 # the number of heads in the multiheadattention models\n","dropout    = 0.2 # the dropout value\n","batch_size = 10 #32\n","val_batch_size = 10 #32, not used right now.\n","epochs     = 50  # The number of epochs\n","\n","TRAIN = True"],"id":"da73442b"},{"cell_type":"markdown","metadata":{"id":"21983a34"},"source":["### Format Dataset\n","\n","Uses a custom dataset class, which is an iterable and callable structure that returns a sample from our dataset. Within this custom dataset, can determine all preprocessing."],"id":"21983a34"},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":25955,"status":"ok","timestamp":1640268093076,"user":{"displayName":"Jeremy Rothschild","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64","userId":"12754514505135179603"},"user_tz":300},"id":"015ae225"},"outputs":[],"source":["# create dataset\n","dataset = dsc.ArxivDataset()\n","#dataset = dsc.WikiTextDataset()\n","\n","#train tokenizer (or use one already trained)\n","tknzr_type = 'BPE'\n","flag_tknzr_train = True\n","flag_tknzr_fast = True\n","\n","_ = dataset.tokenizer(flag_tknzr_train, tknzr_type, flag_tknzr_fast=flag_tknzr_fast)"],"id":"015ae225"},{"cell_type":"markdown","metadata":{"id":"4bba4cb9"},"source":["### Creating DataLoaders\n","\n","Training is done on batches, so we need a way to extract groupings of the data in the appropriate format for our transformer model.\n","Note that for transformers which we are training, dataloaders outputs both src (x[:-1] and tgt ([1:]).\n","The collation of batches for different transformer models we have vary. For HuggingFace it's ( max_len x batch_size ) whereas I think that the Annotated Transformer has ( batch_size x max_len ).\n","\n","I created a custom Dataloader class that wraps splitting the dataset and also outputs different dataloaders for each.\n","\n","NOTE : Do not use the tokenizer before the training if you use num_workers>0!\n","FastTokenizer does not play nicely with forking if you use it before the forking of your data:\n","https://stackoverflow.com/questions/62691279/how-to-disable-tokenizers-parallelism-true-false-warning"],"id":"4bba4cb9"},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":576,"status":"ok","timestamp":1640268106295,"user":{"displayName":"Jeremy Rothschild","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64","userId":"12754514505135179603"},"user_tz":300},"id":"c11048fc"},"outputs":[],"source":["dataloader = dlc.CustomDataloader(dataset, batch_size, max_len_sentence)"],"id":"c11048fc"},{"cell_type":"markdown","metadata":{"id":"e3955854"},"source":["### Selecting model\n","\n","Here we choose which model we shall use for training. For now, I've selected the black box Transformer from HuggingFace because the collate_fn I've written gives the correct input size force it... however this can easily be changed! "],"id":"e3955854"},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":640,"status":"ok","timestamp":1640268619959,"user":{"displayName":"Jeremy Rothschild","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64","userId":"12754514505135179603"},"user_tz":300},"id":"6de7d252"},"outputs":[],"source":["# transformer from huggingface\n","# TODO : Change to the Annotated Transformer if I want\n","model = TransformerModel(dataset.vocab_size, emsize, nhead, nhid, nlayers, dropout).to(device)\n","\n","# criterion\n","criterion = torch.nn.CrossEntropyLoss()#ignore_index=tknzr.get_vocab()[\"<pad>\"])\n","\n","# optimizer\n","paramsAdam  = [{'params' : model.parameters(), 'lr' : 1e-3, 'betas' : (0.9, 0.999), 'eps' : 1e-08, 'weight_decay' : 0.0}]\n","paramsAdamW = [{'params' : model.parameters(), 'lr' : 5e-5, 'betas' : (0.9, 0.999), 'eps' : 1e-08, 'weight_decay' : 0.0}]\n","paramsSGD   = [{'params' : model.parameters(), 'lr' : 0.5, 'momentum' : 0.0, 'dampening' : 0.0, 'weight_decay' : 0.0}]\n","\n","optimizer = torch.optim.SGD( paramsSGD )\n","#optimizer = torch.optim.Adam( paramsAdam )\n","#optimizer = torch.optim.AdamW( paramsAdamW )\n","\n","# scheduler\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95) # 1.0 to signify no decay rate"],"id":"6de7d252"},{"cell_type":"markdown","metadata":{"id":"9780d86f"},"source":["### Training\n","\n","Training loop!"],"id":"9780d86f"},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":65225,"status":"error","timestamp":1640268687934,"user":{"displayName":"Jeremy Rothschild","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64","userId":"12754514505135179603"},"user_tz":300},"id":"75775f0e","outputId":"0e12d1de-7e57-4136-d539-6dbdd2b7046e"},"outputs":[{"output_type":"stream","name":"stdout","text":["10\n","-----------------------------------------------------------------------------------------\n","| end of epoch   1 | time:  1.61s | valid loss 43.76 | valid ppl 10087596252536035328.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch   2 | time:  1.49s | valid loss 48.72 | valid ppl 1437187759369399042048.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch   3 | time:  1.48s | valid loss 41.49 | valid ppl 1043293294236180480.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch   4 | time:  1.50s | valid loss 41.17 | valid ppl 756594599759807360.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch   5 | time:  1.48s | valid loss 40.46 | valid ppl 374725842005733504.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch   6 | time:  1.48s | valid loss 40.03 | valid ppl 243593779033675872.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch   7 | time:  1.50s | valid loss 40.16 | valid ppl 275325823930042816.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch   8 | time:  1.49s | valid loss 39.44 | valid ppl 134921757564103104.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch   9 | time:  1.49s | valid loss 40.12 | valid ppl 266073647013714880.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch  10 | time:  1.49s | valid loss 40.35 | valid ppl 335495646799706432.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch  11 | time:  1.50s | valid loss 39.05 | valid ppl 90638826547363472.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch  12 | time:  1.56s | valid loss 39.06 | valid ppl 91952504219586576.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch  13 | time:  1.50s | valid loss 39.36 | valid ppl 123918659730761008.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch  14 | time:  1.49s | valid loss 39.38 | valid ppl 126089837733495680.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch  15 | time:  1.51s | valid loss 39.50 | valid ppl 142981076694715008.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch  16 | time:  1.48s | valid loss 39.08 | valid ppl 94110878991032960.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch  17 | time:  1.49s | valid loss 39.58 | valid ppl 154247210534911232.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch  18 | time:  1.48s | valid loss 38.64 | valid ppl 60308410514274392.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch  19 | time:  1.51s | valid loss 38.80 | valid ppl 71046037201574768.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch  20 | time:  1.48s | valid loss 38.76 | valid ppl 67996757031318048.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch  21 | time:  1.50s | valid loss 38.57 | valid ppl 56283140597369432.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch  22 | time:  1.49s | valid loss 39.25 | valid ppl 111224450755686704.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch  23 | time:  1.52s | valid loss 39.05 | valid ppl 91110585725430736.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch  24 | time:  1.49s | valid loss 39.33 | valid ppl 120875741842038112.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch  25 | time:  1.54s | valid loss 38.87 | valid ppl 75988075193348048.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch  26 | time:  1.49s | valid loss 37.57 | valid ppl 20751361307763884.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch  27 | time:  1.50s | valid loss 37.11 | valid ppl 13127764900669824.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch  28 | time:  1.50s | valid loss 37.12 | valid ppl 13277077726378844.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch  29 | time:  1.49s | valid loss 38.77 | valid ppl 69139350570836696.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch  30 | time:  1.50s | valid loss 38.46 | valid ppl 50285558898390192.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch  31 | time:  1.50s | valid loss 39.04 | valid ppl 90461107648144304.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch  32 | time:  1.52s | valid loss 38.13 | valid ppl 36178679634069528.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch  33 | time:  1.49s | valid loss 38.04 | valid ppl 33223731672464348.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch  34 | time:  1.50s | valid loss 38.83 | valid ppl 72801212039637200.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch  35 | time:  1.49s | valid loss 38.12 | valid ppl 35807502114406712.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch  36 | time:  1.50s | valid loss 37.27 | valid ppl 15376114032251912.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch  37 | time:  1.50s | valid loss 39.24 | valid ppl 110038307486028096.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch  38 | time:  1.49s | valid loss 38.64 | valid ppl 60240725104597472.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch  39 | time:  1.50s | valid loss 38.22 | valid ppl 39612316543835384.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch  40 | time:  1.50s | valid loss 38.44 | valid ppl 49526896765764472.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch  41 | time:  1.51s | valid loss 37.33 | valid ppl 16355601675837852.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch  42 | time:  1.49s | valid loss 38.40 | valid ppl 47635115798611736.00\n","-----------------------------------------------------------------------------------------\n","10\n","-----------------------------------------------------------------------------------------\n","| end of epoch  43 | time:  1.51s | valid loss 38.11 | valid ppl 35639272286534216.00\n","-----------------------------------------------------------------------------------------\n","10\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-00d0600c364e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mepoch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m89\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Github/Abstract-generator/src/model/train_evaluate.py\u001b[0m in \u001b[0;36mtrain_version_jeremy\u001b[0;34m(model, dataloader, device, vocab_size, epoch, optimizer, scheduler, criterion, max_len)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0mlog_interval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlog_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"  # fasttokenizer should not be used before forking. Something\n","                                                # to figure out. What this does is suppress some warning messages \n","                                                # https://stackoverflow.com/questions/62691279/how-to-disable-tokenizers-parallelism-true-false-warning\n","                                                # doesn't seem to affect the timing though\n","if TRAIN:\n","    best_val_loss = float(\"inf\")\n","    best_model = None\n","    for epoch in range(1, epochs + 1):\n","        epoch_start_time = time.time()\n","        print(len(dataloader.train))\n","        train(model, dataloader.train, device, dataset.vocab_size, epoch, optimizer, scheduler, criterion, max_len_sentence)\n","        val_loss = evaluate(model, dataloader.valid, device, dataset.vocab_size, criterion, max_len_sentence, len(dataloader.dataset_valid))\n","        print('-' * 89)\n","        print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n","              'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n","                                         val_loss, math.exp(val_loss)))\n","                                         # Why is math.exp so large????\n","        print('-' * 89)\n","\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            best_model = model\n","\n","        scheduler.step()\n","\n","    # save best model (two methods)\n","    model_full = settings.DIR_MODELS + os.sep + f'{dataset.name}_epoch{epochs}.pth'\n","    model_weights = settings.DIR_MODELS + os.sep + f'{dataset.name}_weights_epoch{epochs}.pth'\n","    model_full_best = settings.DIR_MODELS + os.sep + f'{dataset.name}_epoch{epochs}_best.pth'\n","    model_weights_best = settings.DIR_MODELS + os.sep + f'{dataset.name}_weights_epoch{epochs}_best.pth'\n","    # approach 1: save model (class) entirely (uses pickle)\n","    torch.save(model, model_full)\n","    torch.save(best_model, model_full_best)\n","    # approach 2: save model weights\n","    torch.save(best_model.state_dict(), model_weights_best)"],"id":"75775f0e"},{"cell_type":"markdown","metadata":{"id":"XM5G4vD0q9TZ"},"source":["### Text Generation\n","\n","Here I've simply taken the code Matt uses to generate text."],"id":"XM5G4vD0q9TZ"},{"cell_type":"code","execution_count":null,"metadata":{"id":"eb6acee1","executionInfo":{"status":"aborted","timestamp":1640267411232,"user_tz":300,"elapsed":138,"user":{"displayName":"Jeremy Rothschild","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64","userId":"12754514505135179603"}}},"outputs":[],"source":["if not TRAIN:\n","    custom_filename = 'arxiv_10000'\n","    custom_epochs = 10\n","    model_full = settings.DIR_MODELS + os.sep + f'{custom_filename}_epoch{custom_epochs}_best.pth'\n","    model_weights = settings.DIR_MODELS + os.sep + f'{custom_filename}_weights_epoch{custom_epochs}_best.pth'\n","    \n","    # approach 1: load model (class) entirely (uses pickle)\n","    model_full_load = torch.load(model_full, map_location=device)\n","\n","    # approach 2: load model weights, need to have some parameter or something \n","    model_load = TransformerModel(vocab_size, emsize, nhead, nhid, nlayers, dropout).to(device)\n","    model_weights_load = model_load.load_state_dict( torch.load(model_weights) )"],"id":"eb6acee1"},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":390},"executionInfo":{"elapsed":803,"status":"error","timestamp":1640268410117,"user":{"displayName":"Jeremy Rothschild","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64","userId":"12754514505135179603"},"user_tz":300},"id":"SoGylu7hq7kI","outputId":"ddadce6b-87b2-4aab-c471-8749c299f584"},"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-c7cd456076ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m generated_text = gen_some_text(\n\u001b[1;32m     15\u001b[0m     \u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_prompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens_to_gen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mngen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     decode_style=decode_style)\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Text prompt:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of tokens to generate:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Github/Abstract-generator/src/model/generate_text.py\u001b[0m in \u001b[0;36mgen_some_text\u001b[0;34m(model, tokenizer, vocab, device, text_prompt, tokens_to_gen, vis, verbose, sidestep_unk, decode_style, decode_seed, decode_beta, decode_sample_topp_threshold)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;31m# 1) tokenize the text prompt and prepare associated src_mask for model.forward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m     \u001b[0mprompt_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# src should be in form ntokens x nbatches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0mnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Github/Abstract-generator/src/model/generate_text.py\u001b[0m in \u001b[0;36mprocess_prompt\u001b[0;34m(dummy_token)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# - if longer than BPTT (context length), truncate to BPTT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         text_split, tokenized_text = tokenize_some_text(tokenizer, vocab,\n\u001b[0;32m---> 62\u001b[0;31m                                                         text=text_prompt)\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Github/Abstract-generator/src/model/generate_text.py\u001b[0m in \u001b[0;36mtokenize_some_text\u001b[0;34m(tokenizer, vocab, text)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \"\"\"\n\u001b[1;32m     22\u001b[0m     \u001b[0mtokenized_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mtokenized_text_ints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenized_text_ints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Github/Abstract-generator/src/model/generate_text.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \"\"\"\n\u001b[1;32m     22\u001b[0m     \u001b[0mtokenized_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mtokenized_text_ints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenized_text_ints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: string indices must be integers"]}],"source":["# inspect both models\n","#print('model_A info...\\n', model_full_load)\n","#print('\\nmodel_B info...\\n', model_weights_load)\n","\n","#print('model_A == model_B:', model_full_load == model_weights_load)\n","#model = model_full_load\n","# Text generation example\n","\n","#model = model_load\n","prompt = 'The dog ran'\n","ngen = 100\n","decode_style = 'sample_topp' #greedy, sample_topp\n","model.to('cpu')\n","generated_text = gen_some_text(\n","    best_model, dataset.transform, 'cpu', max_len_sentence, text_prompt=prompt, tokens_to_gen=ngen, vis=False,\n","    decode_style=decode_style)\n","print(\"Text prompt:\\n\", prompt)\n","print(\"Number of tokens to generate:\", ngen)\n","print(\"Generated_text:\\n\", generated_text)\n","\n","# TODO: alternative generation\n","# currently 'greedy method'\n","# see: https://huggingface.co/blog/how-to-generate"],"id":"SoGylu7hq7kI"},{"cell_type":"code","execution_count":null,"metadata":{"id":"NDDjgoQqjODa","executionInfo":{"status":"aborted","timestamp":1640267411235,"user_tz":300,"elapsed":15,"user":{"displayName":"Jeremy Rothschild","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj61S-ps1fSn3WHOaumL82qcXAixc33zZBJ_THQl4E=s64","userId":"12754514505135179603"}}},"outputs":[],"source":[""],"id":"NDDjgoQqjODa"}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"training_and_evaluation.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"nbformat":4,"nbformat_minor":5}